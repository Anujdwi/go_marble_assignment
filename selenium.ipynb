{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.3 bs4-0.0.2 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    "    ElementClickInterceptedException,\n",
    "    StaleElementReferenceException,\n",
    ")\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_css_selectors(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    css_selectors = []\n",
    "\n",
    "    def extract_selectors(element):\n",
    "        tag = element.name\n",
    "        classes = element.get(\"class\")\n",
    "        class_selector = f\".{'.'.join(classes)}\" if classes else None\n",
    "        id_selector = f\"#{element.get('id')}\" if element.get(\"id\") else None\n",
    "\n",
    "        if class_selector:\n",
    "            css_selectors.append(class_selector)\n",
    "        if id_selector:\n",
    "            css_selectors.append(id_selector)\n",
    "        if tag:\n",
    "            css_selectors.append(tag)\n",
    "\n",
    "        for child in element.children:\n",
    "            if isinstance(child, BeautifulSoup) or isinstance(child, str):\n",
    "                continue\n",
    "            extract_selectors(child)\n",
    "\n",
    "    extract_selectors(soup)\n",
    "    return list(set(css_selectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dynamic_popups(driver):\n",
    "    try:\n",
    "        potential_popups = driver.find_elements(By.CSS_SELECTOR, \"*\")\n",
    "        for element in potential_popups:\n",
    "            try:\n",
    "                style = element.get_attribute(\"style\")\n",
    "                if \"z-index\" in style and \"visibility: visible\" in style:\n",
    "                    close_buttons = element.find_elements(By.CSS_SELECTOR, \"button, a, span\")\n",
    "                    for button in close_buttons:\n",
    "                        if button.is_displayed() and button.is_enabled():\n",
    "                            button.click()\n",
    "                            time.sleep(1)\n",
    "                            return True\n",
    "                    action = ActionChains(driver)\n",
    "                    random_x = random.randint(0, driver.execute_script(\"return window.innerWidth;\"))\n",
    "                    random_y = random.randint(0, driver.execute_script(\"return window.innerHeight;\"))\n",
    "                    action.move_by_offset(random_x, random_y).click().perform()\n",
    "                    time.sleep(1)\n",
    "                    return True\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "            except Exception:\n",
    "                continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_reviews(url, review_tag, author_tag, rating_tag, next_page_button_tag):\n",
    "    service = Service(\"chromedriver.exe\")  # Update this path if necessary\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        all_reviews = []\n",
    "        page_number = 1\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, review_tag)))\n",
    "                while handle_dynamic_popups(driver):\n",
    "                    print(\"Pop-up dismissed. Retrying scraping...\")\n",
    "\n",
    "                review_elements = driver.find_elements(By.CSS_SELECTOR, review_tag)\n",
    "                author_elements = driver.find_elements(By.CSS_SELECTOR, author_tag)\n",
    "                rating_elements = driver.find_elements(By.CSS_SELECTOR, rating_tag)\n",
    "\n",
    "                for review, author, rating in zip(review_elements, author_elements, rating_elements):\n",
    "                    all_reviews.append({\n",
    "                        \"review\": review.text.strip(),\n",
    "                        \"author\": author.text.strip(),\n",
    "                        \"rating\": rating.get_attribute(\"data-score\") or \"N/A\",\n",
    "                    })\n",
    "\n",
    "                print(f\"Page {page_number} scraped successfully with {len(review_elements)} reviews.\")\n",
    "                page_number += 1\n",
    "\n",
    "                try:\n",
    "                    next_page_button = driver.find_element(By.CSS_SELECTOR, next_page_button_tag)\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "                    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, next_page_button_tag))).click()\n",
    "                    time.sleep(1)\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(\"No more pages to scrape or 'Next Page' button not found.\")\n",
    "                    break\n",
    "                except ElementClickInterceptedException:\n",
    "                    handle_dynamic_popups(driver)\n",
    "                    continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping page {page_number}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n",
      ".jdgm-rev__header\n",
      "h4\n",
      ".jdgm-paginate\n",
      ".header.wrapper\n",
      ".jdgm-rev__custom-form\n",
      "#shopify-section-template--19759787049262__16600839769333e113\n",
      ".newsletter-input\n",
      ".template-product.template-product.no-touchevents.image-reveal--mask\n",
      ".jdgm-medal.jdgm--loading\n",
      "br\n",
      ".product_details\n",
      "#menu-open-button\n",
      "#dynamic-checkout-cart\n",
      ".product-variant__input.product-variant-value\n",
      ".underline-animation\n",
      ".jdgm-rev__buyer-badge-wrapper\n",
      ".footer-item.footer-item--copyright\n",
      "nav\n",
      ".cart-continue\n",
      ".jdgm-paginate__page.jdgm-curt\n",
      "#shopify-section-header\n",
      ".product__cart-actions.cart-actions.buttons-holder\n",
      ".menu-meta__link\n",
      ".footer-item.four-tenths.lap--full-width.footer-item--newsletter\n",
      ".aria-hidden\n",
      "#Email-popup\n",
      ".form\n",
      "img\n",
      ".additional-checkout-buttons.additional-checkout-buttons--vertical\n",
      "div\n",
      "b\n",
      ".primary-menu\n",
      ".jdgm-rev__icon\n",
      ".line\n",
      ".jdgm-medals__container\n",
      ".visually-hidden.skip-to-content\n",
      ".jdgm-medal__value\n",
      ".jdgm-rev__title\n",
      "#ViewCart\n",
      "#product-form-template--19759787049262__main\n",
      "#cart\n",
      "h5\n",
      "#shopify-section-popup\n",
      ".product__pricing\n",
      ".jdgm-rev__timestamp.jdgm-spinner\n",
      "#shopify-section-text-columns-with-icons\n",
      "#main\n",
      "sidebar-drawer\n",
      ".product__add-to-cart.button.button--border\n",
      "script\n",
      "#shopify-digital-wallet\n",
      ".jdgm-histogram__percentage\n",
      ".shopify-section.section-w-mobile-padding.ten-tenths.lap--full-width.push-left-one-tenth.lap--push-left-none\n",
      ".analytics\n",
      ".footer-logo\n",
      ".jdgm-rev-widg__summary\n",
      ".pretitle\n",
      ".product-variant__label\n",
      "#apple-pay-shop-capabilities\n",
      ".jdgm-rev-widg__summary-text\n",
      "#FeaturedMedia-34776908726574-wrapper\n",
      ".shopify-section.custom-liquid-container\n",
      ".white-btn\n",
      "#shopify-section-template--19759787049262__166008086886ca712a\n",
      ".sidebar.sidebar--left\n",
      ".jdgm-rev__reply\n",
      "product-page\n",
      "strong\n",
      ".popup-text\n",
      "path\n",
      "footer\n",
      ".footer-links.text-size--larger\n",
      ".jdgm-rev-widg__header\n",
      ".jdgm-rev-widg__body\n",
      ".jdgm-histogram__row\n",
      "#shopify-buyer-consent\n",
      ".product__cart-actions-holder\n",
      ".product__extras.text-size--smaller\n",
      "#shopify-accelerated-checkout-cart\n",
      ".main-image\n",
      ".button.button--border.button--wide\n",
      "#AjaxCartSubtotal\n",
      ".jdgm-rev__actions\n",
      ".jdgm-histogram.jdgm-temp-hidden\n",
      "#toggle-05917d87-b9f3-4cfa-8a38-0150117b1dd6\n",
      ".jdgm-star.jdgm--half\n",
      ".sidebar__close\n",
      ".product__title.h2\n",
      "#shopify-features\n",
      "#shopify-section-footer\n",
      "toggle-tab\n",
      ".jdgm-miracle-styles\n",
      ".jdgm-histogram__bar\n",
      "#shopify-block-AVlMwdXZ1bDdDRVgwK__c7fccf12-e6f0-47c2-b6a0-1b611c4a720f\n",
      ".chart.m-order-1\n",
      "#logo\n",
      ".footer-item__title\n",
      ".newsletter-text.rte\n",
      "#shop-js-analytics\n",
      "#__st\n",
      ".product-variant__container\n",
      ".copper-strip\n",
      "a\n",
      "#CheckOut\n",
      ".product__description.lap--push-left-padding.smaller-lap--push-left-none\n",
      "#shopify-subscription-policy-button\n",
      ".grid-section.subscription-section\n",
      ".sidebar__container\n",
      ".jdgm-rev__votes\n",
      "#shopify-section-template--19759787049262__16600847836f3b1c29\n",
      ".button.button--solid.button--wide.button--align\n",
      "span\n",
      ".shopify-block.shopify-app-block\n",
      ".product__content\n",
      "section\n",
      ".rte\n",
      ".newsletter-form\n",
      ".hidden\n",
      "#Email-block\n",
      ".jdgm-rev-widg__sort-wrapper\n",
      ".close-sidebar\n",
      ".jdgm-spinner\n",
      ".shopify-payment-button__skeleton\n",
      ".close-sidebar__text\n",
      ".footer-item.four-tenths.lap--full-width.push-left-two-tenths.lap--push-left-none.footer-item--text\n",
      "#web-pixels-manager-setup\n",
      "#site-cart-sidebar\n",
      ".cart-items\n",
      ".jdgm-prev-badge\n",
      "ul\n",
      ".ingredient-card\n",
      ".product-variant\n",
      "product-variants\n",
      ".page-content\n",
      "#shopify-accelerated-checkout\n",
      ".logo\n",
      ".jdgm-rev__br\n",
      ".cart\n",
      ".cart__footer.cart--empty\n",
      ".product-page\n",
      ".jdgm-paginate__page\n",
      ".jdgm-rev.jdgm-divider-top\n",
      ".wallet-cart-button-container\n",
      "#Variants-template--19759787049262__main\n",
      ".jdgm-rev__social\n",
      ".shopify-section.mount-popup\n",
      ".jdgm-star.jdgm--on\n",
      ".page-overlay\n",
      ".jdgm-paginate__page.jdgm-paginate__next-page\n",
      "#CartTotal\n",
      ".selected\n",
      ".cart-out\n",
      ".jdgm-prev-badge__text\n",
      ".info\n",
      ".newsletter-submit\n",
      "#product-template--19759787049262__main\n",
      "#deep-penetration\n",
      "#shopify-section-announcement-bar\n",
      "#RechargeWidget_8108919292206\n",
      ".jdgm-widget.jdgm-review-widget\n",
      ".shopify-section.mount-product-page.mount-product-gallery.mount-css-slider.main-product.section-w-margin\n",
      ".jdgm-rev__content\n",
      ".jdgm-settings-script\n",
      ".button.button--solid\n",
      ".product-gallery__item.lap--six-tenths.smaller-lap--smart-width.smaller-lap--push-left-padding\n",
      ".productSelect\n",
      ".dynamic-checkout__content\n",
      ".product__variants\n",
      ".sidebar__menus\n",
      ".jdgm-medals\n",
      ".jdgm-medals-wrapper.jdgm-hidden\n",
      "#newsletter-form-cb26e229-0f34-44da-a191-022d03cc56e4\n",
      "#shopify-section-template--19759787049262__main\n",
      "head\n",
      ".jdgm-prev-badge__stars\n",
      "#CartDetails\n",
      "#key-ingredients\n",
      ".section-image.m-order-1\n",
      ".jdgm-settings-style\n",
      ".jdgm-histogram__row.jdgm-histogram__clear-filter\n",
      "noscript\n",
      ".jdgm-star.jdgm--off\n",
      ".wallet-cart-grid.wallet-cart-grid--skeleton\n",
      "meta\n",
      ".jdgm-widget.jdgm-preview-badge\n",
      ".ten-tenths.lap--twelve-tenths.push-left-one-tenth.lap--push-left-padding\n",
      ".sidebar__menu.sidebar--primary\n",
      ".toggle__title.text-size--smaller\n",
      ".product-size\n",
      ".toggle\n",
      "label\n",
      ".shopify-section.mount-header\n",
      "title\n",
      ".toggle__content.rte\n",
      ".jdgm-rev__source\n",
      "#shopify-block-AeXBLZmxQQ3Y3YU1We__88d6a826-ee26-480c-9272-58c3e2e1a7a4\n",
      "#shopify-section-template--19759787049262__1660086842e93bcee5\n",
      ".menu-meta__count\n",
      ".cart-actions.buttons-holder\n",
      "#judgeme_product_reviews\n",
      ".navigate-back\n",
      "#shopify-section-template--19759787049262__1694590842d3549cd3\n",
      ".jdgm-rev__location\n",
      ".jdgm-rev-widg__summary-stars\n",
      "#recovery-cream-option-title-1-\n",
      ".cart-holder\n",
      ".wallet-cart-button.wallet-cart-button__skeleton\n",
      ".set-mobile-position\n",
      ".popup\n",
      "#27-17-relief-amp-recovery-cream\n",
      ".ingredient-cards\n",
      ".product__quantity\n",
      "#cart-open-button\n",
      ".localization-form-holder\n",
      "form\n",
      ".menu-meta__icon\n",
      ".jdgm-rev__pics\n",
      ".add-to-cart__text\n",
      ".product__form\n",
      ".product-variant__item\n",
      ".sidebar.sidebar--right\n",
      "main\n",
      "modal-box\n",
      "#viewed_product\n",
      "p\n",
      "shopify-payment-terms\n",
      ".footer-item.four-tenths.lap--full-width.footer-item--menus\n",
      ".jdgm-rev__vids\n",
      "product-form\n",
      ".sidebar__footer\n",
      ".jdgm-rev__rating\n",
      ".jdgm-medal__image\n",
      "#header-size-settings\n",
      ".jdgm-histogram__star\n",
      ".product-variant__name\n",
      "#Subscribe-block\n",
      ".newsletter-submit.button.button--solid.button--wide\n",
      ".product__gallery\n",
      ".shopify-block.shopify-app-block.recharge-subscription-widget\n",
      "html\n",
      ".jdgm-histogram__frequency\n",
      "#newsletter-form-popup\n",
      ".two-tenths.lap--five-tenths.palm--full-width\n",
      ".menu-meta\n",
      ".jdgm-rev-widg__paginate-spinner-wrapper\n",
      "#captcha-bootstrap\n",
      ".jdgm-rev__author\n",
      ".button.button--border.button--align\n",
      ".shopify-payment-button__button\n",
      "input\n",
      ".menu-opener\n",
      "select\n",
      "#modal-popup\n",
      "cart-form\n",
      "main-header\n",
      "h1\n",
      "button\n",
      ".content.m-order-2\n",
      "small\n",
      ".jdgm-histogram__bar-content\n",
      "link\n",
      ".container\n",
      ".jdgm-rev__buyer-badge\n",
      ".newsletter-input-holder\n",
      ".jdgm-rev-widg__reviews\n",
      ".product__header\n",
      "#add-to-cart-template--19759787049262__main\n",
      ".jdgm-rev-widg\n",
      "h2\n",
      "svg\n",
      "shopify-accelerated-checkout-cart\n",
      "#site-menu-sidebar\n",
      ".jdgm-write-rev-link\n",
      ".logo-img\n",
      ".site-cart-heading.sidebar__caption\n",
      ".footer-item.four-tenths.lap--full-width.push-left-two-tenths.lap--push-left-none.footer-item--menus\n",
      ".shopify-payment-button__more-options.shopify-payment-button__skeleton\n",
      "style\n",
      ".grid-section\n",
      "product-header\n",
      ".contact-form\n",
      ".no-js\n",
      ".popup-close\n",
      ".shopify-section.section-w-margin\n",
      ".jdgm-rev-widg__title\n",
      "shopify-accelerated-checkout\n",
      ".shopify-section.no-overflow\n",
      "option\n",
      "#AjaxCartForm\n",
      ".header-holder\n",
      ".jdgm-paginate__page.jdgm-paginate__last-page\n",
      ".shopify-payment-button\n",
      ".h4.popup-title\n",
      ".jdgm-rev__author-wrapper\n",
      "#shopify-accelerated-checkout-cart-grid-with-margin-top\n",
      ".sidebar__content\n",
      ".visually-hidden\n",
      ".cart__count.hidden\n",
      ".shopify-section.mount-announcement\n",
      "#Subscribe-popup\n",
      ".boomerang\n",
      ".menu-opener__icon\n",
      "template\n",
      ".p1\n",
      "h3\n",
      ".content\n",
      ".jdgm-script\n",
      "#shopify-block-AWlpaOTBsbGlVS0p5V__be734d2d-7807-42df-8cd0-873a6c941d97\n",
      ".footer-links-body\n",
      ".jdgm-medal-wrapper\n",
      ".jdgm-temp-hiding-style\n",
      "li\n",
      ".jdgm-rev__body\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fetch the webpage content\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all elements\n",
    "elements = soup.find_all(True)  # 'True' means it finds all tags\n",
    "\n",
    "# Initialize lists to store CSS selectors\n",
    "css_selectors = []\n",
    "\n",
    "# Loop through all elements\n",
    "for element in elements:\n",
    "    # Get the tag name\n",
    "    tag = element.name\n",
    "    \n",
    "    # Get the class (if exists)\n",
    "    classes = element.get(\"class\")\n",
    "    class_selector = f\".{'.'.join(classes)}\" if classes else None\n",
    "\n",
    "    # Get the id (if exists)\n",
    "    id_selector = f\"#{element.get('id')}\" if element.get(\"id\") else None\n",
    "\n",
    "    # Construct possible CSS selectors\n",
    "    if class_selector:\n",
    "        css_selectors.append(class_selector)\n",
    "    if id_selector:\n",
    "        css_selectors.append(id_selector)\n",
    "    if tag:\n",
    "        css_selectors.append(tag)\n",
    "\n",
    "# Remove duplicates by converting the list to a set\n",
    "unique_selectors = set(css_selectors)\n",
    "\n",
    "# Print all unique CSS selectors\n",
    "for selector in unique_selectors:\n",
    "    print(selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jdgm-rev__body<---review\n",
    "jdgm-rev__author<---authors name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "Author: Shawna Churchill\n",
      "Review: I love this stuff!\n",
      "--------------------------------------------------\n",
      "Review 2:\n",
      "Author: Tania Patterson\n",
      "Review: It‚Äôs amazing\n",
      "--------------------------------------------------\n",
      "Review 3:\n",
      "Author: Francis Alvir\n",
      "Review: So far so good . Still in trial stage\n",
      "--------------------------------------------------\n",
      "Review 4:\n",
      "Author: G.P.\n",
      "Review: So far so good\n",
      "--------------------------------------------------\n",
      "Review 5:\n",
      "Author: Melvaree Witherspoon\n",
      "Review: I absolutely love this product! I‚Äôve been using it before my workouts, and it‚Äôs been a total game-changer. One of my favorite things about it is that it doesn‚Äôt smell like medicine‚Äîit has such a pleasant scent! I recently let my business partner use it on her knee that‚Äôs been giving her trouble, and she loved it just as much as I do. It‚Äôs effective, and enjoyable to use. I‚Äôve even been sharing it on my social media because I believe in it so much. Great job, 27:17 team‚Äîthank you for creating such an amazing product!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_reviews(url):\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all review elements\n",
    "    review_elements = soup.find_all(class_=\"jdgm-rev__body\")\n",
    "    author_elements = soup.find_all(class_=\"jdgm-rev__author\")\n",
    "    rating_elements =soup.find_all(class_=\"jdgm-row-rating\")\n",
    "    \n",
    "    # Extract reviews and authors\n",
    "    reviews = []\n",
    "    for review, author,rating in zip(review_elements, author_elements,rating_elements):\n",
    "        review_text = review.get_text(strip=True)\n",
    "        author_name = author.get_text(strip=True)\n",
    "        reviews.append({\"review\": review_text, \"author\": author_name})\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "\n",
    "# Fetch and print reviews\n",
    "reviews = fetch_reviews(url)\n",
    "for idx, review in enumerate(reviews, 1):\n",
    "    print(f\"Review {idx}:\")\n",
    "    print(f\"Author: {review['author']}\")\n",
    "    print(f\"Review: {review['review']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "Author: Shawna Churchill\n",
      "Rating: 5 stars\n",
      "Review: I love this stuff!\n",
      "--------------------------------------------------\n",
      "Review 2:\n",
      "Author: Tania Patterson\n",
      "Rating: 4 stars\n",
      "Review: It‚Äôs amazing\n",
      "--------------------------------------------------\n",
      "Review 3:\n",
      "Author: Francis Alvir\n",
      "Rating: 5 stars\n",
      "Review: So far so good . Still in trial stage\n",
      "--------------------------------------------------\n",
      "Review 4:\n",
      "Author: G.P.\n",
      "Rating: 5 stars\n",
      "Review: So far so good\n",
      "--------------------------------------------------\n",
      "Review 5:\n",
      "Author: Melvaree Witherspoon\n",
      "Rating: 5 stars\n",
      "Review: I absolutely love this product! I‚Äôve been using it before my workouts, and it‚Äôs been a total game-changer. One of my favorite things about it is that it doesn‚Äôt smell like medicine‚Äîit has such a pleasant scent! I recently let my business partner use it on her knee that‚Äôs been giving her trouble, and she loved it just as much as I do. It‚Äôs effective, and enjoyable to use. I‚Äôve even been sharing it on my social media because I believe in it so much. Great job, 27:17 team‚Äîthank you for creating such an amazing product!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_reviews(url):\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all review elements\n",
    "    review_elements = soup.find_all(class_=\"jdgm-rev__body\")\n",
    "    author_elements = soup.find_all(class_=\"jdgm-rev__author\")\n",
    "    rating_elements = soup.find_all(class_=\"jdgm-rev__rating\")\n",
    "    \n",
    "    # Extract reviews, authors, and ratings\n",
    "    reviews = []\n",
    "    for review, author, rating in zip(review_elements, author_elements, rating_elements):\n",
    "        review_text = review.get_text(strip=True)\n",
    "        author_name = author.get_text(strip=True)\n",
    "        rating_score = rating.get(\"data-score\", \"N/A\")  # Extract 'data-score' or use 'N/A' if missing\n",
    "        reviews.append({\n",
    "            \"review\": review_text,\n",
    "            \"author\": author_name,\n",
    "            \"rating\": rating_score\n",
    "        })\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "\n",
    "# Fetch and print reviews\n",
    "reviews = fetch_reviews(url)\n",
    "for idx, review in enumerate(reviews, 1):\n",
    "    print(f\"Review {idx}:\")\n",
    "    print(f\"Author: {review['author']}\")\n",
    "    print(f\"Rating: {review['rating']} stars\")\n",
    "    print(f\"Review: {review['review']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\anuj dwivedi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\anuj dwivedi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (2024.12.14)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\anuj dwivedi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.7 MB 6.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/9.7 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.7 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.3/9.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, typing_extensions, sniffio, pysocks, pycparser, h11, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.3.0 cffi-1.17.1 h11-0.14.0 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.27.1 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 typing_extensions-4.12.2 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully with 5 reviews.\n",
      "Click intercepted on page 2: Message: element click intercepted: Element <a class=\"jdgm-paginate__page jdgm-paginate__next-page\" data-page=\"2\" aria-label=\"Page 2\" tabindex=\"0\" rel=\"next\" role=\"button\"></a> is not clickable at point (664, 15). Other element would receive the click: <div role=\"dialog\" aria-modal=\"true\" aria-label=\"POPUP Form\" class=\"needsclick  kl-private-reset-css-Xuajs1\" style=\"display: flex; z-index: 90000; position: fixed; left: 0px; top: 0px; width: 100%; height: 100%; justify-content: center; align-items: center; overflow: clip auto; background-color: rgba(20, 20, 20, 0.6); animation-timing-function: ease; animation-play-state: running; animation-iteration-count: 1; animation-fill-mode: forwards; animation-delay: 0s; animation-duration: 0.35s; animation-name: klaviyo-fadein;\">...</div>\n",
      "  (Session info: chrome=131.0.6778.265)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7529280D5+2992373]\n",
      "\t(No symbol) [0x00007FF7525BBFD0]\n",
      "\t(No symbol) [0x00007FF75245590A]\n",
      "\t(No symbol) [0x00007FF7524B0F2E]\n",
      "\t(No symbol) [0x00007FF7524AE9CC]\n",
      "\t(No symbol) [0x00007FF7524ABBA6]\n",
      "\t(No symbol) [0x00007FF7524AAB01]\n",
      "\t(No symbol) [0x00007FF75249CD40]\n",
      "\t(No symbol) [0x00007FF7524CF36A]\n",
      "\t(No symbol) [0x00007FF75249C596]\n",
      "\t(No symbol) [0x00007FF7524CF580]\n",
      "\t(No symbol) [0x00007FF7524EF584]\n",
      "\t(No symbol) [0x00007FF7524CF113]\n",
      "\t(No symbol) [0x00007FF75249A918]\n",
      "\t(No symbol) [0x00007FF75249BA81]\n",
      "\tGetHandleVerifier [0x00007FF752986A2D+3379789]\n",
      "\tGetHandleVerifier [0x00007FF75299C32D+3468109]\n",
      "\tGetHandleVerifier [0x00007FF752990043+3418211]\n",
      "\tGetHandleVerifier [0x00007FF75271C78B+847787]\n",
      "\t(No symbol) [0x00007FF7525C757F]\n",
      "\t(No symbol) [0x00007FF7525C2FC4]\n",
      "\t(No symbol) [0x00007FF7525C315D]\n",
      "\t(No symbol) [0x00007FF7525B2979]\n",
      "\tBaseThreadInitThunk [0x00007FFCC3FF259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFCC526AF38+40]\n",
      "\n",
      "Error scraping page 2: name 'ActionChains' is not defined\n",
      "Review 1:\n",
      "Author: Shawna Churchill\n",
      "Rating: 5 stars\n",
      "Review: I love this stuff!\n",
      "--------------------------------------------------\n",
      "Review 2:\n",
      "Author: Tania Patterson\n",
      "Rating: 4 stars\n",
      "Review: It‚Äôs amazing\n",
      "--------------------------------------------------\n",
      "Review 3:\n",
      "Author: Francis Alvir\n",
      "Rating: 5 stars\n",
      "Review: So far so good . Still in trial stage\n",
      "--------------------------------------------------\n",
      "Review 4:\n",
      "Author: G.P.\n",
      "Rating: 5 stars\n",
      "Review: So far so good\n",
      "--------------------------------------------------\n",
      "Review 5:\n",
      "Author: Melvaree Witherspoon\n",
      "Rating: 5 stars\n",
      "Review: I absolutely love this product! I‚Äôve been using it before my workouts, and it‚Äôs been a total game-changer. One of my favorite things about it is that it doesn‚Äôt smell like medicine‚Äîit has such a pleasant scent! I recently let my business partner use it on her knee that‚Äôs been giving her trouble, and she loved it just as much as I do. It‚Äôs effective, and enjoyable to use. I‚Äôve even been sharing it on my social media because I believe in it so much. Great job, 27:17 team‚Äîthank you for creating such an amazing product!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "import time\n",
    "\n",
    "def fetch_all_reviews(url):\n",
    "    # Set up Selenium WebDriver\n",
    "    service = Service(\"C:/Users/Anuj Dwivedi/python api/chromedriver.exe\")  # Update this path\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()  # Maximize window for better visibility\n",
    "\n",
    "    try:\n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)  # Wait for elements to load\n",
    "\n",
    "        all_reviews = []\n",
    "        page_number = 1  # Track the current page number for debugging\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Wait for the reviews section to load\n",
    "                wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"jdgm-rev__body\")))\n",
    "\n",
    "                # Get the current page source and parse it with BeautifulSoup\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                # Find all review elements\n",
    "                review_elements = soup.find_all(class_=\"jdgm-rev__body\")\n",
    "                author_elements = soup.find_all(class_=\"jdgm-rev__author\")\n",
    "                rating_elements = soup.find_all(class_=\"jdgm-rev__rating\")\n",
    "\n",
    "                # Extract reviews, authors, and ratings\n",
    "                for review, author, rating in zip(review_elements, author_elements, rating_elements):\n",
    "                    review_text = review.get_text(strip=True)\n",
    "                    author_name = author.get_text(strip=True)\n",
    "                    rating_score = rating.get(\"data-score\", \"N/A\")  # Extract 'data-score' or use 'N/A' if missing\n",
    "                    all_reviews.append({\n",
    "                        \"review\": review_text,\n",
    "                        \"author\": author_name,\n",
    "                        \"rating\": rating_score\n",
    "                    })\n",
    "\n",
    "                print(f\"Page {page_number} scraped successfully with {len(review_elements)} reviews.\")\n",
    "                page_number += 1\n",
    "\n",
    "                # Scroll the \"Next Page\" button into view and click it\n",
    "                try:\n",
    "                    next_page_button = driver.find_element(By.CSS_SELECTOR, \"a.jdgm-paginate__next-page\")\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "                    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.jdgm-paginate__next-page\"))).click()\n",
    "                    time.sleep(2)  # Small pause to ensure the page loads\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(\"No more pages to scrape or 'Next Page' button not found.\")\n",
    "                    break\n",
    "                except ElementClickInterceptedException as e:\n",
    "                    print(f\"Click intercepted on page {page_number}: {str(e)}\")\n",
    "                    ActionChains(driver).move_to_element_with_offset(next_page_button, 0, 0).click().perform()\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping page {page_number}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # Ensure the browser is closed properly\n",
    "        driver.quit()\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "\n",
    "# Fetch and print reviews\n",
    "if __name__ == \"__main__\":\n",
    "    reviews = fetch_all_reviews(url)\n",
    "    for idx, review in enumerate(reviews, 1):\n",
    "        print(f\"Review {idx}:\")\n",
    "        print(f\"Author: {review['author']}\")\n",
    "        print(f\"Rating: {review['rating']} stars\")\n",
    "        print(f\"Review: {review['review']}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27:17 | Relief & Recovery Cream\n",
      "Skip to content\n",
      "0\n",
      "Close\n",
      "Back\n",
      "Home\n",
      "Shop Now\n",
      "Our Mission\n",
      "Ambassador Application\n",
      "Wholesale Partnerships\n",
      "Close\n",
      "0 products in your cart\n",
      "0\n",
      "Total: $0.00\n",
      "Shipping & taxes calculated at checkout\n",
      "View Cart\n",
      "Update cart\n",
      "Checkout    ¬†     One or more of the items in your cart is a recurring or deferred purchase. By continuing, I agree to the cancellation policy and authorize you to charge my payment method at the prices, frequency and dates listed on this page until my order is fulfilled or I cancel, if permitted.\n",
      "Continue browsing\n",
      "420 reviews\n",
      "[BACKORDER] Relief & Recovery Cream\n",
      "100 ml / 3.4 oz\n",
      "üì¶ All backorders will ship January 17th üì¶\n",
      "NEW IMPROVED FORMULA COMING JANUARY 17TH\n",
      "We‚Äôve updated our formula for even faster absorption and results. Click below to view full ingredients list.\n",
      "Description\n",
      "A pain-relief cream created for high-performance athletes that helps speed up the body's natural recovery process and remove the source of discomfort. Now available for everybody looking to feel better faster, get back on the path and back in the game.\n",
      "Usage\n",
      "Apply anywhere on the body with discomfort for immediate relief.\n",
      "Apply before work outs to warm up your muscle fibers and speed up recovery.\n",
      "Use daily or as needed.\n",
      "Select Title\n",
      "Default Title\n",
      "Default Title\n",
      "- $38.25\n",
      "Add to cart - $38.25\n",
      "This item is a recurring or deferred purchase. By continuing, I agree to the cancellation policy and authorize you to charge my payment method at the prices, frequency and dates listed on this page until my order is fulfilled or I cancel, if permitted.\n",
      "Click For Ingredients ‚¨á\n",
      "Water (Aqua), Cocos Nucifera (Coconut) Oil, Glycerin, Caprylic/Capric Triglyceride, Cetearyl Alcohol, Dimethicone, TerpenesBlend, Phenoxyethanol, Menthol, Menthyl Lactate, Ethylhexylglycerin, Carbomer, Copper Tripeptide-1, Tetrasodium Glutamate Diacetate, Citric Acid, Sodium Hydroxide, Anthemis, Nobilis Flower Oil, MSM Powder, Dodecahydro, TetramethyInapthofuran, Eucalyptus Globulus Leaf Oil, Eugenia, Caryophyllus (Clove) Leaf Oil, Gamma-Octalactone, Gamma-Caprolactone, Lavandula Hybrida Oil, Litsea Cubeba Fruit Oil, Pelargonium Graveolens Flower Oil, Salvia Sclarea (Clary) Oil, Triethyl Citrate, Glyceryl Stearate SE, Green 5 (CI 61570), Yellow 5 (Cl 19140), Citrus Limon (Lemon) Peel Oil, Hydroxyethylcellulose, Arnica Extract\n",
      "KEY INGREDIENTS\n",
      "How it works\n",
      "GHK-Cu (Copper Peptide)\n",
      "A protein that responds to tissue injuries by activating blood vessel growth and anti-inflammatory agents. This helps reduce inflammation (easing muscle soreness and body pain), promote tissue repair (helping your muscles recover faster), and improve circulation (delivering nutrients to sore or damaged areas for quicker healing).\n",
      "OptiMSM\n",
      "The purest form of MSM (Methylsulfonylmethane), sourced in the United States, and helps with joint health (reducing stiffness and discomfort), skin health (improving elasticity and reducing signs of aging), and muscle recovery (helping sore muscles feel better)\n",
      "Arnica Extract\n",
      "Sourced from the Arnica Montana Plant, a yellow flower that grows in mountain regions that's packed with natural compounds like helanins and flavonoids which help naturally calm the feeling of pain while to boosting blood flow to help prevent bruising and speed up the healing of broken blood vessels.\n",
      "Essential Oils\n",
      "A blend of 27 Muscle Essential Oils each intentionally and purposefully selected to give a soothing sensation, non-greasy texture, and uplifting aroma.\n",
      "Formulated For Deep Penetration\n",
      "The Relief & Recovery Cream's blend of GHK-Cu (copper peptide), terpenes, and essential oils promote recovery by addressing the source of your discomfort rather than masking it. Penetrating deep through the skin and down to the bone, relieving your discomfort in the process.\n",
      "Real Relief For Real People.\n",
      "It‚Äôs tough to be your best when you‚Äôre not feeling your best.\n",
      "It's tough to work, to exercise, to focus, even to relax when you're in pain\n",
      "And truth is, anyone on the path of being a little better today than they were yesterday is likely to have some aches in the process.\n",
      "Which is why we've even partnered up with chiropractors like Dr. Camacho to create the perfect recovery product to get you back in the game.\n",
      "Relief on your schedule.\n",
      "Subscribe to our recurring subscription program and recieve $5 off of your order, delivered at your pace, on your schedule.\n",
      "Need a new bottle every month? Every other week? Every 6 months? No worries. We‚Äôve got you covered. Send us a message and we‚Äôll take care of you.\n",
      "Select ‚ÄúSubscribe & Save‚Äù when adding to cart.\n",
      "Back to top\n",
      "Customer Reviews     Based on 420 reviews  Write a review        77% (324)        6% (24)        5% (23)        5% (19)        7% (30)    98.899.3       S           Shawna Churchill          I love this stuff!               T           Tania Patterson          It‚Äôs amazing               F           Francis Alvir          So far so good . Still in trial stage               G           G.P.          So far so good               M           Melvaree Witherspoon        Game-Changer With a Pleasant Scent I absolutely love this product! I‚Äôve been using it before my workouts, and it‚Äôs been a total game-changer. One of my favorite things about it is that it doesn‚Äôt smell like medicine‚Äîit has such a pleasant scent! I recently let my business partner use it on her knee that‚Äôs been giving her trouble, and she loved it just as much as I do. It‚Äôs effective, and enjoyable to use. I‚Äôve even been sharing it on my social media because I believe in it so much. Great job, 27:17 team‚Äîthank you for creating such an amazing product!             123\n",
      "Navigation\n",
      "Home\n",
      "Shop Now\n",
      "Our Mission\n",
      "Ambassador Application\n",
      "Wholesale Partnerships\n",
      "Support\n",
      "Contact\n",
      "Become a Partner\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Shipping Policy\n",
      "Returns\n",
      "GET THE LATEST\n",
      "Your email\n",
      "Submit\n",
      "Join the newsletter. No spam. Only the stuff that matters. Privacy policy.Disclaimer\n",
      "*These statements have not been evaluated by the Food and Drug Administration (FDA). Supplements are not intended to diagnose, treat, cure, mitigate or prevent any disease. This information is not a substitute for medical advice or treatment. Always consult your physician before starting any new supplement, exercise or diet plan.\n",
      "Proverbs 27:17 ‚ÄúAs iron sharpens iron, so one man sharpens another.‚Äù\n",
      "Owned by Paradise Valley Investments, LLC\n",
      "PopupStay up to date on the latest product releases, special offers & news by signing up for our newsletter.Read our privacy policy.\n",
      "Your email\n",
      "Submit\n",
      "Close\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_url(url):\n",
    "    try:\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error if the request fails\n",
    "\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Extract all text from the webpage\n",
    "        page_text = soup.get_text()\n",
    "\n",
    "        # Clean up the text by removing excessive whitespace\n",
    "        clean_text = \"\\n\".join(line.strip() for line in page_text.splitlines() if line.strip())\n",
    "\n",
    "        return clean_text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# URL of the webpage to extract text from\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "\n",
    "# Extract and print the text\n",
    "text = extract_text_from_url(url)\n",
    "if text:\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully with 5 reviews.\n",
      "Click intercepted on page 2: Message: element click intercepted: Element <a class=\"jdgm-paginate__page jdgm-paginate__next-page\" data-page=\"2\" aria-label=\"Page 2\" tabindex=\"0\" rel=\"next\" role=\"button\"></a> is not clickable at point (664, 15). Other element would receive the click: <div role=\"dialog\" aria-modal=\"true\" aria-label=\"POPUP Form\" class=\"needsclick  kl-private-reset-css-Xuajs1\" style=\"display: flex; z-index: 90000; position: fixed; left: 0px; top: 0px; width: 100%; height: 100%; justify-content: center; align-items: center; overflow: clip auto; background-color: rgba(20, 20, 20, 0.6); animation-timing-function: ease; animation-play-state: running; animation-iteration-count: 1; animation-fill-mode: forwards; animation-delay: 0s; animation-duration: 0.35s; animation-name: klaviyo-fadein;\">...</div>\n",
      "  (Session info: chrome=131.0.6778.265)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7F64580D5+2992373]\n",
      "\t(No symbol) [0x00007FF7F60EBFD0]\n",
      "\t(No symbol) [0x00007FF7F5F8590A]\n",
      "\t(No symbol) [0x00007FF7F5FE0F2E]\n",
      "\t(No symbol) [0x00007FF7F5FDE9CC]\n",
      "\t(No symbol) [0x00007FF7F5FDBBA6]\n",
      "\t(No symbol) [0x00007FF7F5FDAB01]\n",
      "\t(No symbol) [0x00007FF7F5FCCD40]\n",
      "\t(No symbol) [0x00007FF7F5FFF36A]\n",
      "\t(No symbol) [0x00007FF7F5FCC596]\n",
      "\t(No symbol) [0x00007FF7F5FFF580]\n",
      "\t(No symbol) [0x00007FF7F601F584]\n",
      "\t(No symbol) [0x00007FF7F5FFF113]\n",
      "\t(No symbol) [0x00007FF7F5FCA918]\n",
      "\t(No symbol) [0x00007FF7F5FCBA81]\n",
      "\tGetHandleVerifier [0x00007FF7F64B6A2D+3379789]\n",
      "\tGetHandleVerifier [0x00007FF7F64CC32D+3468109]\n",
      "\tGetHandleVerifier [0x00007FF7F64C0043+3418211]\n",
      "\tGetHandleVerifier [0x00007FF7F624C78B+847787]\n",
      "\t(No symbol) [0x00007FF7F60F757F]\n",
      "\t(No symbol) [0x00007FF7F60F2FC4]\n",
      "\t(No symbol) [0x00007FF7F60F315D]\n",
      "\t(No symbol) [0x00007FF7F60E2979]\n",
      "\tBaseThreadInitThunk [0x00007FFFC2A2259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFFC2C2AF38+40]\n",
      "\n",
      "Error scraping page 2: name 'ActionChains' is not defined\n",
      "Review 1:\n",
      "Author: Shawna Churchill\n",
      "Rating: 5 stars\n",
      "Review: I love this stuff!\n",
      "--------------------------------------------------\n",
      "Review 2:\n",
      "Author: Tania Patterson\n",
      "Rating: 4 stars\n",
      "Review: It‚Äôs amazing\n",
      "--------------------------------------------------\n",
      "Review 3:\n",
      "Author: Francis Alvir\n",
      "Rating: 5 stars\n",
      "Review: So far so good . Still in trial stage\n",
      "--------------------------------------------------\n",
      "Review 4:\n",
      "Author: G.P.\n",
      "Rating: 5 stars\n",
      "Review: So far so good\n",
      "--------------------------------------------------\n",
      "Review 5:\n",
      "Author: Melvaree Witherspoon\n",
      "Rating: 5 stars\n",
      "Review: I absolutely love this product! I‚Äôve been using it before my workouts, and it‚Äôs been a total game-changer. One of my favorite things about it is that it doesn‚Äôt smell like medicine‚Äîit has such a pleasant scent! I recently let my business partner use it on her knee that‚Äôs been giving her trouble, and she loved it just as much as I do. It‚Äôs effective, and enjoyable to use. I‚Äôve even been sharing it on my social media because I believe in it so much. Great job, 27:17 team‚Äîthank you for creating such an amazing product!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "import time\n",
    "\n",
    "# Step 1: Function to fetch and extract tags from a webpage\n",
    "def extract_css_selectors(url):\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all elements\n",
    "    elements = soup.find_all(True)  # 'True' means it finds all tags\n",
    "\n",
    "    # Initialize lists to store CSS selectors\n",
    "    css_selectors = []\n",
    "\n",
    "    # Loop through all elements\n",
    "    for element in elements:\n",
    "        # Get the tag name\n",
    "        tag = element.name\n",
    "\n",
    "        # Get the class (if exists)\n",
    "        classes = element.get(\"class\")\n",
    "        class_selector = f\".{'.'.join(classes)}\" if classes else None\n",
    "\n",
    "        # Get the id (if exists)\n",
    "        id_selector = f\"#{element.get('id')}\" if element.get(\"id\") else None\n",
    "\n",
    "        # Construct possible CSS selectors\n",
    "        if class_selector:\n",
    "            css_selectors.append(class_selector)\n",
    "        if id_selector:\n",
    "            css_selectors.append(id_selector)\n",
    "        if tag:\n",
    "            css_selectors.append(tag)\n",
    "\n",
    "    # Remove duplicates by converting the list to a set\n",
    "    unique_selectors = set(css_selectors)\n",
    "\n",
    "    return unique_selectors\n",
    "\n",
    "# Step 2: Generalized function to scrape reviews using extracted tags and URL\n",
    "def fetch_all_reviews(url, review_tag, author_tag, rating_tag):\n",
    "    # Set up Selenium WebDriver\n",
    "    service = Service(\"C:/Users/Anuj Dwivedi/python api/chromedriver.exe\")  # Update this path\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()  # Maximize window for better visibility\n",
    "\n",
    "    try:\n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)  # Wait for elements to load\n",
    "\n",
    "        all_reviews = []\n",
    "        page_number = 1  # Track the current page number for debugging\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Wait for the reviews section to load\n",
    "                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, review_tag)))\n",
    "\n",
    "                # Get the current page source and parse it with BeautifulSoup\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                # Find all review elements using the passed review_tag, author_tag, and rating_tag\n",
    "                review_elements = soup.select(review_tag)\n",
    "                author_elements = soup.select(author_tag)\n",
    "                rating_elements = soup.select(rating_tag)\n",
    "\n",
    "                # Extract reviews, authors, and ratings\n",
    "                for review, author, rating in zip(review_elements, author_elements, rating_elements):\n",
    "                    review_text = review.get_text(strip=True)\n",
    "                    author_name = author.get_text(strip=True)\n",
    "                    rating_score = rating.get(\"data-score\", \"N/A\")  # Extract 'data-score' or use 'N/A' if missing\n",
    "                    all_reviews.append({\n",
    "                        \"review\": review_text,\n",
    "                        \"author\": author_name,\n",
    "                        \"rating\": rating_score\n",
    "                    })\n",
    "\n",
    "                print(f\"Page {page_number} scraped successfully with {len(review_elements)} reviews.\")\n",
    "                page_number += 1\n",
    "\n",
    "                # Scroll the \"Next Page\" button into view and click it\n",
    "                try:\n",
    "                    next_page_button = driver.find_element(By.CSS_SELECTOR, \"a.jdgm-paginate__next-page\")\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "                    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.jdgm-paginate__next-page\"))).click()\n",
    "                    time.sleep(2)  # Small pause to ensure the page loads\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(\"No more pages to scrape or 'Next Page' button not found.\")\n",
    "                    break\n",
    "                except ElementClickInterceptedException as e:\n",
    "                    print(f\"Click intercepted on page {page_number}: {str(e)}\")\n",
    "                    ActionChains(driver).move_to_element_with_offset(next_page_button, 0, 0).click().perform()\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping page {page_number}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # Ensure the browser is closed properly\n",
    "        driver.quit()\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Step 3: Use the above functions with dynamic parameters\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "\n",
    "# Extract CSS selectors for the review section, author, and rating from the URL\n",
    "unique_selectors = extract_css_selectors(url)\n",
    "\n",
    "# These could be dynamic, so let's assume we know which CSS selectors to use for this specific site\n",
    "review_tag = \".jdgm-rev__body\"\n",
    "author_tag = \".jdgm-rev__author\"\n",
    "rating_tag = \".jdgm-rev__rating\"\n",
    "\n",
    "# Fetch and print reviews\n",
    "if __name__ == \"__main__\":\n",
    "    reviews = fetch_all_reviews(url, review_tag, author_tag, rating_tag)\n",
    "    for idx, review in enumerate(reviews, 1):\n",
    "        print(f\"Review {idx}:\")\n",
    "        print(f\"Author: {review['author']}\")\n",
    "        print(f\"Rating: {review['rating']} stars\")\n",
    "        print(f\"Review: {review['review']}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully with 5 reviews.\n",
      "Page 2 scraped successfully with 5 reviews.\n",
      "Page 3 scraped successfully with 5 reviews.\n",
      "Error scraping page 4: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.265)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF685B480D5+2992373]\n",
      "\t(No symbol) [0x00007FF6857DBFD0]\n",
      "\t(No symbol) [0x00007FF68567590A]\n",
      "\t(No symbol) [0x00007FF68564F4F5]\n",
      "\t(No symbol) [0x00007FF6856F63A7]\n",
      "\t(No symbol) [0x00007FF68570EE72]\n",
      "\t(No symbol) [0x00007FF6856EF113]\n",
      "\t(No symbol) [0x00007FF6856BA918]\n",
      "\t(No symbol) [0x00007FF6856BBA81]\n",
      "\tGetHandleVerifier [0x00007FF685BA6A2D+3379789]\n",
      "\tGetHandleVerifier [0x00007FF685BBC32D+3468109]\n",
      "\tGetHandleVerifier [0x00007FF685BB0043+3418211]\n",
      "\tGetHandleVerifier [0x00007FF68593C78B+847787]\n",
      "\t(No symbol) [0x00007FF6857E757F]\n",
      "\t(No symbol) [0x00007FF6857E2FC4]\n",
      "\t(No symbol) [0x00007FF6857E315D]\n",
      "\t(No symbol) [0x00007FF6857D2979]\n",
      "\tBaseThreadInitThunk [0x00007FFFC2A2259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFFC2C2AF38+40]\n",
      "\n",
      "Saved 15 reviews to 'reviews.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    "    ElementClickInterceptedException,\n",
    "    StaleElementReferenceException,\n",
    ")\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "# Function to handle all pop-ups dynamically, including random clicks\n",
    "def handle_dynamic_popups(driver):\n",
    "    try:\n",
    "        potential_popups = driver.find_elements(By.CSS_SELECTOR, \"*\")\n",
    "        for element in potential_popups:\n",
    "            try:\n",
    "                style = element.get_attribute(\"style\")\n",
    "                if \"z-index\" in style and \"visibility: visible\" in style:\n",
    "                    close_buttons = element.find_elements(By.CSS_SELECTOR, \"button, a, span\")\n",
    "                    for button in close_buttons:\n",
    "                        if button.is_displayed() and button.is_enabled():\n",
    "                            button.click()\n",
    "                            time.sleep(1)\n",
    "                            return True\n",
    "                    action = ActionChains(driver)\n",
    "                    random_x = random.randint(0, driver.execute_script(\"return window.innerWidth;\"))\n",
    "                    random_y = random.randint(0, driver.execute_script(\"return window.innerHeight;\"))\n",
    "                    action.move_by_offset(random_x, random_y).click().perform()\n",
    "                    time.sleep(1)\n",
    "                    return True\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "            except Exception:\n",
    "                continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "# Function to scrape reviews\n",
    "def fetch_all_reviews(url, review_tag, author_tag, rating_tag, next_page_button_tag):\n",
    "    service = Service(\"chromedriver.exe\")  # Update this path\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        all_reviews = []\n",
    "        page_number = 1\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, review_tag)))\n",
    "                while handle_dynamic_popups(driver):\n",
    "                    print(\"Pop-up dismissed. Retrying scraping...\")\n",
    "\n",
    "                review_elements = driver.find_elements(By.CSS_SELECTOR, review_tag)\n",
    "                author_elements = driver.find_elements(By.CSS_SELECTOR, author_tag)\n",
    "                rating_elements = driver.find_elements(By.CSS_SELECTOR, rating_tag)\n",
    "\n",
    "                for review, author, rating in zip(review_elements, author_elements, rating_elements):\n",
    "                    all_reviews.append({\n",
    "                        \"review\": review.text.strip(),\n",
    "                        \"author\": author.text.strip(),\n",
    "                        \"rating\": rating.get_attribute(\"data-score\") or \"N/A\",\n",
    "                    })\n",
    "\n",
    "                print(f\"Page {page_number} scraped successfully with {len(review_elements)} reviews.\")\n",
    "                page_number += 1\n",
    "\n",
    "                try:\n",
    "                    next_page_button = driver.find_element(By.CSS_SELECTOR, next_page_button_tag)\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "                    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, next_page_button_tag))).click()\n",
    "                    time.sleep(1)\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(\"No more pages to scrape or 'Next Page' button not found.\")\n",
    "                    break\n",
    "                except ElementClickInterceptedException:\n",
    "                    handle_dynamic_popups(driver)\n",
    "                    continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping page {page_number}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "\n",
    "# CSS Selectors for this specific site\n",
    "review_tag = \".jdgm-rev__body\"\n",
    "author_tag = \".jdgm-rev__author\"\n",
    "rating_tag = \".jdgm-rev__rating\"\n",
    "next_page_button_tag = \"a.jdgm-paginate__page.jdgm-paginate__next-page\"\n",
    "\n",
    "\n",
    "# Fetch and save reviews in JSON\n",
    "if __name__ == \"__main__\":\n",
    "    reviews = fetch_all_reviews(url, review_tag, author_tag, rating_tag, next_page_button_tag)\n",
    "    with open(\"reviews.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(reviews, file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saved {len(reviews)} reviews to 'reviews.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the bottom of the page.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Optional: Start browser maximized\n",
    "service = Service(\"chromedriver.exe\")  # Replace with the correct path to your chromedriver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Open the website\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"  # Replace with your target website\n",
    "driver.get(url)\n",
    "\n",
    "# Scroll to the bottom of the page\n",
    "scroll_pause_time = 2  # Time to wait between scrolls in seconds\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to the bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)  # Wait for page to load after scrolling\n",
    "    \n",
    "    # Calculate new scroll height and compare with last height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:  # If the height is the same, we've reached the bottom\n",
    "        print(\"Reached the bottom of the page.\")\n",
    "        break\n",
    "    last_height = new_height\n",
    "    tim\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Function to extract unique tags\n",
    "def extract_unique_tags(url):\n",
    "    # Set up Selenium WebDriver\n",
    "    service = Service(\"chromedriver.exe\")  # Update this path\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    try:\n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Wait until the page loads\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"html\")))\n",
    "\n",
    "        # Find all elements in the page\n",
    "        elements = driver.find_elements(By.XPATH, \"//*\")\n",
    "\n",
    "        # Extract unique tags\n",
    "        unique_tags = set()\n",
    "        for element in elements:\n",
    "            tag = element.tag_name\n",
    "            unique_tags.add(tag)\n",
    "\n",
    "        # Return the unique tags\n",
    "        return unique_tags\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# URL of the website to scrape\n",
    "url = \"https://www.example.com\"  # Replace with your desired URL\n",
    "\n",
    "# Fetch unique tags from the webpage\n",
    "if __name__ == \"__main__\":\n",
    "    unique_tags = extract_unique_tags(url)\n",
    "    print(\"Unique tags on the page:\")\n",
    "    for tag in unique_tags:\n",
    "        print(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No popup detected.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Configure Selenium WebDriver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "service = Service(\"chromedriver.exe\")  # Update with the correct path\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Open the website\n",
    "url = \"https://2717recovery.com/products/recovery-cream\"\n",
    "driver.get(url)\n",
    "\n",
    "# Function to randomly click on the screen\n",
    "def random_screen_click(driver):\n",
    "    # Get the window size\n",
    "    window_width = driver.execute_script(\"return window.innerWidth\")\n",
    "    window_height = driver.execute_script(\"return window.innerHeight\")\n",
    "\n",
    "    # Generate random x, y coordinates\n",
    "    x = random.randint(0, window_width - 1)\n",
    "    y = random.randint(0, window_height - 1)\n",
    "\n",
    "    # Use JavaScript to simulate the click\n",
    "    driver.execute_script(f\"document.elementFromPoint({x}, {y}).click();\")\n",
    "    print(f\"Clicked at random coordinates: ({x}, {y})\")\n",
    "\n",
    "# Check for popups and randomly click\n",
    "try:\n",
    "    time.sleep(25)  # Wait for potential popups to load\n",
    "    # Example: Detecting a specific popup (adjust selector to your use case)\n",
    "    popup_detected = driver.find_element(By.CSS_SELECTOR, \".popup-class\")  # Update with the actual selector\n",
    "\n",
    "    if popup_detected:\n",
    "        print(\"Popup detected, attempting to close it by random click.\")\n",
    "        random_screen_click(driver)\n",
    "\n",
    "        # Verify if the popup is closed\n",
    "        try:\n",
    "            time.sleep(2)  # Allow time for the click to take effect\n",
    "            driver.find_element(By.CSS_SELECTOR, \".popup-class\")  # Check if popup still exists\n",
    "            print(\"Popup not closed.\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Popup closed successfully.\")\n",
    "except NoSuchElementException:\n",
    "    print(\"No popup detected.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while waiting for reviews section: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6BFF180D5+2992373]\n",
      "\t(No symbol) [0x00007FF6BFBABFD0]\n",
      "\t(No symbol) [0x00007FF6BFA4590A]\n",
      "\t(No symbol) [0x00007FF6BFA9926E]\n",
      "\t(No symbol) [0x00007FF6BFA9955C]\n",
      "\t(No symbol) [0x00007FF6BFAE27D7]\n",
      "\t(No symbol) [0x00007FF6BFABF3AF]\n",
      "\t(No symbol) [0x00007FF6BFADF584]\n",
      "\t(No symbol) [0x00007FF6BFABF113]\n",
      "\t(No symbol) [0x00007FF6BFA8A918]\n",
      "\t(No symbol) [0x00007FF6BFA8BA81]\n",
      "\tGetHandleVerifier [0x00007FF6BFF76A2D+3379789]\n",
      "\tGetHandleVerifier [0x00007FF6BFF8C32D+3468109]\n",
      "\tGetHandleVerifier [0x00007FF6BFF80043+3418211]\n",
      "\tGetHandleVerifier [0x00007FF6BFD0C78B+847787]\n",
      "\t(No symbol) [0x00007FF6BFBB757F]\n",
      "\t(No symbol) [0x00007FF6BFBB2FC4]\n",
      "\t(No symbol) [0x00007FF6BFBB315D]\n",
      "\t(No symbol) [0x00007FF6BFBA2979]\n",
      "\tBaseThreadInitThunk [0x00007FFFC2A2259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFFC2C2AF38+40]\n",
      "\n",
      "Unique tags on the page:\n",
      "link\n",
      "h4\n",
      "span\n",
      "title\n",
      "html\n",
      "meta\n",
      "noscript\n",
      "script\n",
      "body\n",
      "input\n",
      "div\n",
      "img\n",
      "button\n",
      "form\n",
      "head\n",
      "a\n",
      "i\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Function to extract unique tags\n",
    "def extract_unique_tags(url):\n",
    "    # Set up Selenium WebDriver\n",
    "    service = Service(\"chromedriver.exe\")  # Update this path\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    try:\n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Wait for the body or reviews section to ensure the page is loaded\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "        # Ensure that the reviews section is visible\n",
    "        # For Amazon, the review section can be identified by a specific tag\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-asin]\")))\n",
    "        except Exception as e:\n",
    "            print(\"Error while waiting for reviews section:\", e)\n",
    "\n",
    "        # Find all elements on the page\n",
    "        elements = driver.find_elements(By.XPATH, \"//*\")\n",
    "\n",
    "        # Extract unique tags\n",
    "        unique_tags = set()\n",
    "        for element in elements:\n",
    "            tag = element.tag_name\n",
    "            unique_tags.add(tag)\n",
    "\n",
    "        # Return the unique tags\n",
    "        return unique_tags\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# URL of the website to scrape\n",
    "url = \"https://www.amazon.in/Puma-Mens-ATTACANTO-Black-Poison-Football/dp/B0C2V6GNZS/ref=asc_df_B0C2V6GNZS/?tag=googleshopdes-21&linkCode=df0&hvadid=710066525906&hvpos=&hvnetw=g&hvrand=9537220491062594138&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9062061&hvtargid=pla-2283327688705&mcid=6482f7f7a59f3914adbe2c782f60512c&gad_source=1&th=1&psc=1\"  # Replace with your desired URL\n",
    "\n",
    "# Fetch unique tags from the webpage\n",
    "if __name__ == \"__main__\":\n",
    "    unique_tags = extract_unique_tags(url)\n",
    "    print(\"Unique tags on the page:\")\n",
    "    for tag in unique_tags:\n",
    "        print(tag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
