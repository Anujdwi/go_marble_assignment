{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import *\n",
    "import json\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_url(url):\n",
    "    try:\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error if the request fails\n",
    "\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Extract all text from the webpage\n",
    "        page_text = soup.get_text()\n",
    "\n",
    "        # Clean up the text by removing excessive whitespace\n",
    "        clean_text = \"\\n\".join(line.strip() for line in page_text.splitlines() if line.strip())\n",
    "\n",
    "        return clean_text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_text(text):\n",
    "    \"\"\"Extract JSON from text response, with multiple fallback methods\"\"\"\n",
    "    # First try: direct JSON parsing\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Second try: find JSON-like structure\n",
    "    try:\n",
    "        json_match = re.search(r'\\[.*\\]', text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "    except (json.JSONDecodeError, AttributeError):\n",
    "        pass\n",
    "\n",
    "    # Third try: extract individual review objects\n",
    "    try:\n",
    "        reviews = []\n",
    "        matches = re.finditer(r'\\{\\s*\"review\":[^}]+\\}', text, re.DOTALL)\n",
    "        for match in matches:\n",
    "            try:\n",
    "                review = json.loads(match.group())\n",
    "                reviews.append(review)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        if reviews:\n",
    "            return reviews\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(url):\n",
    "    \"\"\"\n",
    "    Scrapes content from a single page.\n",
    "    Returns the HTML content of the page.\n",
    "    \"\"\"\n",
    "    service = Service(\"chromedriver.exe\")  # Update path as needed\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()\n",
    "    page_content = \"\"\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Wait for content to load\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "        # Get page content\n",
    "        page_content = driver.page_source\n",
    "        print(\"Scraped page content successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping page: {str(e)}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    print(\"Page Content:\", page_content[:500])\n",
    "\n",
    "    return page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(prompt):\n",
    "    \"\"\"Send a query to local Ollama server with improved response handling\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3.2\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Debug: print the response text\n",
    "        print(\"Debug - Ollama raw response:\", response.text)\n",
    "\n",
    "        result = response.json()\n",
    "        if 'response' not in result:\n",
    "            print(\"Debug - Unexpected Ollama response format:\", result)\n",
    "            raise Exception(\"Unexpected response format from Ollama\")\n",
    "\n",
    "        return result['response']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Debug - Ollama API error: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_split_text(text, max_chunk_size):\n",
    "    \"\"\"\n",
    "    Splits text into chunks, ensuring JSON structures are not broken.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for line in text.splitlines():\n",
    "        if len(current_chunk) + len(line) + 1 > max_chunk_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = line\n",
    "        else:\n",
    "            current_chunk += \"\\n\" + line\n",
    "    if current_chunk.strip():\n",
    "        chunks.append(current_chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pagination_selector(url):\n",
    "    \"\"\"\n",
    "    Asks Ollama to identify the pagination selector from the page.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Get all elements that might be pagination buttons\n",
    "    potential_elements = soup.find_all(['a', 'button', 'div'], class_=lambda x: x and ('next' in x.lower() or 'pagination' in x.lower()))\n",
    "    selectors = []\n",
    "    for element in potential_elements:\n",
    "        if element.get('class'):\n",
    "            selectors.append(f\".{'.'.join(element.get('class'))}\")\n",
    "        if element.get('id'):\n",
    "            selectors.append(f\"#{element.get('id')}\")\n",
    "    \n",
    "    if not selectors:\n",
    "        return None\n",
    "\n",
    "    prompt = f\"\"\"Analyze these potential pagination selectors and identify which one is most likely the 'Next Page' button:\n",
    "{json.dumps(selectors, indent=2)}\n",
    "\n",
    "\n",
    "\n",
    "Return only the most likely selector as a string, no other text.\"\"\"\n",
    "    try:\n",
    "        response = query_ollama(prompt)\n",
    "        return response.strip().strip('\"').strip(\"'\")\n",
    "    except Exception:\n",
    "        print(\"Debug - Ollama failed to identify the selector. Manual input required.\")\n",
    "        return input(\"Enter the pagination selector manually (CSS format): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews_from_content(page_content):\n",
    "    \"\"\"\n",
    "    Asks Ollama to extract reviews from the page content\n",
    "    \"\"\"\n",
    "    # Clean the HTML content first\n",
    "    soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "    # Remove script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.decompose()\n",
    "\n",
    "    # Get text content\n",
    "    text = soup.get_text()\n",
    "    if not text.strip():\n",
    "        print(\"Debug - Empty text content after cleaning HTML.\")\n",
    "        return []\n",
    "\n",
    "    # Clean up whitespace\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    text = ' '.join(line for line in lines if line)\n",
    "    print(\"Debug - Extracted text:\", text[:500])  # Print first 500 characters\n",
    "\n",
    "    # Prepare prompt\n",
    "    prompt = \"\"\"Extract all reviews from this webpage content. For each review, identify:\n",
    "    1. The review text\n",
    "    2. The author/username\n",
    "    3. The rating (if present)\n",
    "\n",
    "    Return the results as a JSON array of objects, each with 'review', 'author', and 'rating' fields. Example format:\n",
    "    [\n",
    "        {\n",
    "            \"review\": \"review text here\",\n",
    "            \"author\": \"username here\",\n",
    "            \"rating\": \"5\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    Webpage content:\n",
    "    \"\"\"\n",
    "    print(\"Prepared Prompt for Ollama:\", prompt[:500])  # Check the first 500 characters of the prompt\n",
    "\n",
    "    # Split content into chunks if too long\n",
    "    max_chunk_size = 4000\n",
    "    chunks = safe_split_text(text, max_chunk_size)\n",
    "\n",
    "    all_reviews = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            response = query_ollama(prompt + chunk)\n",
    "            chunk_reviews = json.loads(response)  # Add a check to verify the response is valid JSON\n",
    "            all_reviews.extend(chunk_reviews)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error processing chunk (JSON decode error): {str(e)}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reviews(reviews, filename=\"reviews.json\"):\n",
    "    \"\"\"\n",
    "    Save the reviews to a JSON file\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(reviews, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before running this script, make sure:\n",
      "1. Ollama is installed (https://ollama.ai/download)\n",
      "2. You've pulled the llama3.2 model: Run 'ollama pull llama3.2'\n",
      "3. Ollama server is running: Run 'ollama serve' in a terminal\n",
      "\n",
      "Press Enter when ready, or Ctrl+C to exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping page content...\n",
      "Scraped page content successfully\n",
      "Page Content: <html class=\"no-js\" lang=\"en\" style=\"--header-padding: 14px; --header-logo: 48px; --header-size: 76px; --grid-perfect-width: 1263px; --rc-text-color: #040404; --rc-details-icon-color: #191D48; --rc-active-background-color: #efefef; --rc-active-text-color: #000000; --rc-popup-link-color: #FFFFFF; --rc-popup-text-color: #FFFFFF; --rc-popup-background-color: #191D48;\"><head>\n",
      "\n",
      "  <meta charset=\"utf-8\">\n",
      "  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> \n",
      "  <meta name=\"viewport\" content=\"width=dev\n",
      "\n",
      "Extracting reviews from content...\n",
      "Debug - Extracted text: 27:17 | Relief & Recovery Cream Skip to content 0 Close Back Home Shop Now Our Mission Ambassador Application Wholesale Partnerships Close 0 products in your cart 0 Total: $0.00 Shipping & taxes calculated at checkout View Cart Update cart Checkout          One or more of the items in your cart is a recurring or deferred purchase. By continuing, I agree to the cancellation policy and authorize you to charge my payment method at the prices, frequency and dates listed on this page until my order i\n",
      "Prepared Prompt for Ollama: Extract all reviews from this webpage content. For each review, identify:\n",
      "    1. The review text\n",
      "    2. The author/username\n",
      "    3. The rating (if present)\n",
      "\n",
      "    Return the results as a JSON array of objects, each with 'review', 'author', and 'rating' fields. Example format:\n",
      "    [\n",
      "        {\n",
      "            \"review\": \"review text here\",\n",
      "            \"author\": \"username here\",\n",
      "            \"rating\": \"5\"\n",
      "        }\n",
      "    ]\n",
      "\n",
      "    Webpage content:\n",
      "    \n",
      "Debug - Ollama raw response: {\"model\":\"llama3.2\",\"created_at\":\"2025-01-16T17:42:01.4897548Z\",\"response\":\"I'm happy to help you with your request, but I need more information from you. You haven't provided the webpage content. Please share the URL or paste the HTML content of the page you'd like me to extract reviews from.\\n\\nOnce I have the content, I'll be able to assist you in extracting the reviews and returning them in the format you specified.\",\"done\":true,\"done_reason\":\"stop\",\"context\":[128006,9125,128007,271,38766,1303,33025,2696,25,6790,220,2366,18,271,128009,128006,882,128007,271,30059,682,8544,505,420,45710,2262,13,1789,1855,3477,11,10765,512,262,220,16,13,578,3477,1495,198,262,220,17,13,578,3229,14,5223,198,262,220,18,13,578,10959,320,333,3118,696,262,3494,279,3135,439,264,4823,1358,315,6302,11,1855,449,364,19981,518,364,3170,518,323,364,22696,6,5151,13,13688,3645,512,262,2330,286,341,310,330,19981,794,330,19981,1495,1618,761,310,330,3170,794,330,5223,1618,761,310,330,22696,794,330,20,702,286,457,262,10661,262,5000,2964,2262,512,257,128009,128006,78191,128007,271,40,2846,6380,311,1520,499,449,701,1715,11,719,358,1205,810,2038,505,499,13,1472,9167,956,3984,279,45710,2262,13,5321,4430,279,5665,477,25982,279,9492,2262,315,279,2199,499,4265,1093,757,311,8819,8544,505,382,12805,358,617,279,2262,11,358,3358,387,3025,311,7945,499,304,60508,279,8544,323,13758,1124,304,279,3645,499,5300,13],\"total_duration\":13472966000,\"load_duration\":4626038600,\"prompt_eval_count\":132,\"prompt_eval_duration\":3826000000,\"eval_count\":74,\"eval_duration\":5014000000}\n",
      "Error processing chunk (JSON decode error): Expecting value: line 1 column 1 (char 0)\n",
      "Debug - Ollama raw response: {\"model\":\"llama3.2\",\"created_at\":\"2025-01-16T17:43:29.7736732Z\",\"response\":\"Here is the extracted review data in JSON format:\\n\\n[\\n    {\\n        \\\"review\\\": \\\"I love this stuff!\\\",\\n        \\\"author\\\": \\\"Shawna Churchill\\\",\\n        \\\"rating\\\": null\\n    },\\n    {\\n        \\\"review\\\": \\\"It’s amazing\\\",\\n        \\\"author\\\": \\\"Tania Patterson\\\",\\n        \\\"rating\\\": null\\n    },\\n    {\\n        \\\"review\\\": \\\"So far so good. Still in trial stage\\\",\\n        \\\"author\\\": \\\"Francis Alvir\\\",\\n        \\\"rating\\\": null\\n    },\\n    {\\n        \\\"review\\\": \\\"So far so good\\\",\\n        \\\"author\\\": \\\"G.P.\\\",\\n        \\\"rating\\\": null\\n    },\\n    {\\n        \\\"review\\\": \\\"Game-Changer With a Pleasant Scent I absolutely love this product! I’ve been using it before my workouts, and it’s been a total game-changer. One of my favorite things about it is that it doesn’t smell like medicine—it has such a pleasant scent! I recently let my business partner use it on her knee that’s been giving her trouble, and she loved it just as much as I do. It’s effective, and enjoyable to use. I’ve even been sharing it on my social media because I believe in it so much. Great job, 27:17 team—thank you for creating such an amazing product!\\\",\\n        \\\"author\\\": \\\"Melvaree Witherspoon\\\",\\n        \\\"rating\\\": null\\n    }\\n]\\n\\nNote that all reviews are missing ratings as they were not explicitly stated in the webpage content.\",\"done\":true,\"done_reason\":\"stop\",\"context\":[128006,9125,128007,271,38766,1303,33025,2696,25,6790,220,2366,18,271,128009,128006,882,128007,271,30059,682,8544,505,420,45710,2262,13,1789,1855,3477,11,10765,512,262,220,16,13,578,3477,1495,198,262,220,17,13,578,3229,14,5223,198,262,220,18,13,578,10959,320,333,3118,696,262,3494,279,3135,439,264,4823,1358,315,6302,11,1855,449,364,19981,518,364,3170,518,323,364,22696,6,5151,13,13688,3645,512,262,2330,286,341,310,330,19981,794,330,19981,1495,1618,761,310,330,3170,794,330,5223,1618,761,310,330,22696,794,330,20,702,286,457,262,10661,262,5000,2964,2262,512,262,220,1544,25,1114,765,53495,612,35011,30800,26869,311,2262,220,15,13330,6984,5492,14355,4800,5751,24098,45672,7473,56516,23663,34322,13330,220,15,3956,304,701,7558,220,15,10884,25,400,15,13,410,24907,612,13426,16997,520,28363,2806,13416,5666,7558,57835,257,4194,257,3861,477,810,315,279,3673,304,701,7558,374,264,46350,477,27334,7782,13,3296,14691,11,358,7655,311,279,36935,4947,323,37926,499,311,6900,856,8323,1749,520,279,7729,11,11900,323,13003,10212,389,420,2199,3156,856,2015,374,41834,477,358,9299,11,422,15480,13,15353,32421,220,12819,8544,510,16218,13715,60,53495,612,35011,30800,220,1041,16116,611,220,18,13,19,25616,11410,241,99,2052,1203,8076,690,8448,6186,220,1114,339,11410,241,99,16560,40540,1308,22449,28924,59169,7837,1753,84587,52,8812,220,1114,3701,1226,4070,6177,1057,15150,369,1524,10819,44225,323,3135,13,9369,3770,311,1684,2539,14293,1160,13,7817,362,6784,48712,4843,12932,3549,369,1579,58574,23579,430,8779,4732,709,279,2547,596,5933,13654,1920,323,4148,279,2592,315,44776,13,4800,2561,369,16470,3411,311,2733,2731,10819,11,636,1203,389,279,1853,323,1203,304,279,1847,13,25585,21194,12660,389,279,2547,449,44776,369,14247,16337,13,21194,1603,990,23651,311,8369,709,701,16124,49774,323,4732,709,13654,13,5560,7446,477,439,4460,13,8593,11106,8058,11106,8058,11106,482,400,1987,13,914,3861,7394,7782,400,1987,13,914,29673,612,3665,220,717,4,400,1644,13,2287,7955,32,502,16893,315,13654,690,387,3288,389,701,9899,13,2360,29672,11,5719,477,9299,701,15493,30194,1236,10326,810,1131,72604,555,2758,311,7558,482,400,1987,13,914,4497,8323,2671,220,1115,1537,374,264,46350,477,27334,7782,13,3296,14691,11,358,7655,311,279,36935,4947,323,37926,499,311,6900,856,8323,1749,520,279,7729,11,11900,323,13003,10212,389,420,2199,3156,856,2015,374,41834,477,358,9299,11,422,15480,13,9369,1789,52275,2928,105,229,10164,320,32,44932,705,356,42488,452,1791,333,2473,320,7489,27357,8,15895,11,480,68590,258,11,8171,44280,11547,391,2265,1183,343,68590,579,11,356,7870,78908,45396,11,8289,774,37273,11,10335,2821,288,46100,11,2405,12052,4223,774,39710,11,49693,8619,11,386,21341,4010,445,533,349,11,14693,4010,17757,4010,23797,3913,258,11,69577,26429,11,43640,12639,375,47309,12,16,11,50862,13075,47876,8444,332,92166,7923,68323,349,11,18002,2265,50234,11,83541,40602,87,579,11,90232,285,11,19554,121038,43786,15895,11,68591,44756,11,423,536,936,67229,11,50862,2453,774,88,644,391,339,1073,27105,11,469,1791,5893,418,355,63388,19990,27967,15895,11,41159,59386,11,92664,5237,25734,355,320,34,31153,8,27967,15895,11,58782,93526,278,533,606,11,58782,7813,391,1098,533,606,11,43950,438,5724,10320,1347,4849,15895,11,39351,37541,18521,71853,44187,15895,11,24587,71921,2411,74842,337,729,43786,15895,11,8375,20708,328,566,4903,320,5176,661,8,15895,11,12639,42972,18002,7853,11,79183,22228,75,3441,277,349,5161,11,7997,220,20,320,11487,220,21385,2031,705,26541,220,20,320,5176,220,7529,1272,705,18002,20962,13903,263,320,43,7439,8,89694,15895,11,40602,4223,42972,5997,360,974,11,36194,3074,23673,12282,2006,38,96494,50,2650,433,4375,48584,42,7813,84,320,34,18994,5250,47309,8,362,13128,430,31680,311,20438,15319,555,72192,6680,27274,6650,323,7294,67595,13307,13,1115,8779,8108,37140,320,68,4522,16124,36366,2136,323,2547,6784,705,12192,20438,13023,320,8823,287,701,24569,11993,10819,705,323,7417,35855,320,75828,287,37493,311,36366,477,20727,5789,369,39392,21730,570,16963,72,4931,44,578,10748,267,1376,315,68591,320,44,42972,82,360,13474,18244,774,2194,705,42211,304,279,3723,4273,11,323,8779,449,10496,2890,320,265,1072,6253,70334,323,44776,705,6930,2890,320,318,782,4504,95916,323,18189,12195,315,30084,705,323,16124,13654,320,8823,287,36366,24569,2733,2731,8,36194,3074,23673,328,54492,505,279,36194,3074,37105,18317,11,264,14071,23153,430,28815,304,16700,13918,430,596,19937,449,5933,32246,1093,11591,276,1354,323,18779,263,17390,902,1520,18182,19858,279,8430,315,6784,1418,311,56028,6680,6530,311,1520,5471,43100,3876,323,4732,709,279,21730,315,11102,6680,31080,13,48833,507,8839,362,20955,315,220,1544,68427,48833,507,8839,1855,37304,323,7580,3725,4183,311,3041,264,65464,37392,11,2536,2427,265,6539,10651,11,323,95609,55279,13,3459,7913,1789,18682,13597,74954,578,53495,612,35011,30800,596,20955,315,48584,42,7813,84,320,66,18994,72249,705,2024,2821,288,11,323,7718,32462,12192,13654,555,28118,279,2592,315,701,44776,4856,1109,79176,433,13,13597,17820,1113,5655,1555,279,6930,323,1523,311,279,17685,11,59644,4504,701,44776,304,279,1920,13,8976,53495,1789,8976,9029,13,1102,753,11292,311,387,701,1888,994,499,3207,539,8430,701,1888,13,1102,596,11292,311,990,11,311,10368,11,311,5357,11,1524,311,12234,994,499,2351,304,6784,1628,8206,374,11,5606,389,279,1853,315,1694,264,2697,2731,3432,1109,814,1051,13985,374,4461,311,617,1063,264,8696,304,279,1920,13,16299,374,3249,584,3077,1524,53319,709,449,77301,21846,1093,2999,13,8215,64529,311,1893,279,4832,13654,2027,311,636,499,1203,304,279,1847,13,53495,389,701,9899,13,28369,311,1057,46350,15493,2068,323,1421,19704,400,20,1022,315,701,2015,11,12886,520,701,18338,11,389,701,9899,13,14998,264,502,16893,1475,2305,30,7357,1023,2046,30,7357,220,21,4038,30,2360,38145,13,1226,4070,2751,499,9960,13,11244,603,264,1984,323,584,4805,1935,2512,315,499,13,8593,1054,29673,612,10467,863,994,7999,311,7558,13,6984,311,1948,12557,19832,262,220,19,13,3174,704,315,220,20,20817,389,220,12819,8544,2119,2258,555,20819,17777,286,220,16723,286,220,1187,286,220,1419,286,220,777,286,220,966,220,3580,682,8544,9842,264,3477,220,3264,13,22889,13,18,55658,555,20819,17777,7648,35390,60713,19767,69630,19767,8442,29485,29485,5629,20114,5629,7648,47654,220,1721,14,2589,14,2366,20,36285,3458,58274,692,358,3021,420,6392,0,692,220,1721,14,2705,14,2366,20,350,9345,58734,692,1102,753,8056,692,220,717,14,966,14,2366,19,26184,1708,46957,692,2100,3117,779,1695,662,16782,304,9269,6566,692,220,717,14,1627,14,2366,19,480,1087,13,692,2100,3117,779,1695,692,220,717,14,1114,14,2366,19,11220,85,548,68,3161,388,33076,286,4140,30653,4091,3161,264,64912,328,1189,358,11112,3021,420,2027,0,358,4070,1027,1701,433,1603,856,46944,11,323,433,753,1027,264,2860,1847,11843,4091,13,3861,315,856,7075,2574,922,433,374,430,433,3250,1431,22843,1093,16088,44603,706,1778,264,24729,41466,0,358,6051,1095,856,2626,8427,1005,433,389,1077,22095,430,753,1027,7231,1077,12544,11,323,1364,10456,433,1120,439,1790,439,358,656,13,1102,753,7524,11,323,32180,311,1005,13,358,4070,1524,1027,11821,433,389,856,3674,3772,1606,358,4510,304,433,779,1790,13,8681,2683,11,220,1544,25,1114,2128,2345,58517,499,369,6968,1778,459,8056,2027,0,286,220,4513,18464,5492,14355,4800,5751,24098,45672,7473,56516,23663,34322,9365,9359,51378,264,32413,20163,315,5475,19406,11216,24907,11216,5295,8049,3247,445,62766,4718,2613,30270,16877,279,20846,13,2360,26396,13,8442,279,6392,430,13146,13,19406,4947,89232,353,9673,12518,617,539,1027,26126,555,279,12369,323,26166,17128,320,82169,570,92410,527,539,10825,311,58681,11,4322,11,27208,11,50460,477,5471,904,8624,13,1115,2038,374,539,264,28779,369,6593,9650,477,6514,13,24119,8666,701,28378,1603,6041,904,502,22822,11,10368,477,10173,3197,13,1322,56039,220,1544,25,1114,1054,2170,11245,17676,729,11245,11,779,832,893,17676,729,2500,2029,86193,555,48691,13345,77990,11,15620,47290,39202,709,311,2457,389,279,5652,2027,19786,11,3361,6209,612,3754,555,16351,709,369,1057,20846,6639,1057,12625,4947,13,4718,2613,30270,13330,20819,17777,128009,128006,78191,128007,271,8586,374,279,28532,3477,828,304,4823,3645,1473,9837,262,341,286,330,19981,794,330,40,3021,420,6392,34536,286,330,3170,794,330,2059,675,3458,58274,761,286,330,22696,794,854,198,262,1173,262,341,286,330,19981,794,330,2181,753,8056,761,286,330,3170,794,330,51,9345,58734,761,286,330,22696,794,854,198,262,1173,262,341,286,330,19981,794,330,4516,3117,779,1695,13,16782,304,9269,6566,761,286,330,3170,794,330,81428,285,1708,46957,761,286,330,22696,794,854,198,262,1173,262,341,286,330,19981,794,330,4516,3117,779,1695,761,286,330,3170,794,330,38,1087,10560,286,330,22696,794,854,198,262,1173,262,341,286,330,19981,794,330,4973,30653,4091,3161,264,64912,328,1189,358,11112,3021,420,2027,0,358,4070,1027,1701,433,1603,856,46944,11,323,433,753,1027,264,2860,1847,11843,4091,13,3861,315,856,7075,2574,922,433,374,430,433,3250,1431,22843,1093,16088,44603,706,1778,264,24729,41466,0,358,6051,1095,856,2626,8427,1005,433,389,1077,22095,430,753,1027,7231,1077,12544,11,323,1364,10456,433,1120,439,1790,439,358,656,13,1102,753,7524,11,323,32180,311,1005,13,358,4070,1524,1027,11821,433,389,856,3674,3772,1606,358,4510,304,433,779,1790,13,8681,2683,11,220,1544,25,1114,2128,2345,58517,499,369,6968,1778,459,8056,2027,34536,286,330,3170,794,330,40249,85,548,68,3161,388,33076,761,286,330,22696,794,854,198,262,457,2595,9290,430,682,8544,527,7554,18594,439,814,1051,539,21650,11224,304,279,45710,2262,13],\"total_duration\":85702536500,\"load_duration\":35775400,\"prompt_eval_count\":1697,\"prompt_eval_duration\":59999000000,\"eval_count\":309,\"eval_duration\":25663000000}\n",
      "Error processing chunk (JSON decode error): Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Found 0 reviews:\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#     print(\"Before running this script, make sure:\")\n",
    "#     print(\"1. Ollama is installed (https://ollama.ai/download)\")\n",
    "#     print(\"2. You've pulled the llama3.2 model: Run 'ollama pull llama3.2'\")\n",
    "#     print(\"3. Ollama server is running: Run 'ollama serve' in a terminal\")\n",
    "#     print(\"\\nPress Enter when ready, or Ctrl+C to exit\")\n",
    "#     input()\n",
    "\n",
    "#     url = input(\"Enter the URL to scrape: \")\n",
    "\n",
    "#     try:\n",
    "#         # Scrape the page content\n",
    "#         print(\"\\nScraping page content...\")\n",
    "#         page_content = get_page_content(url)\n",
    "\n",
    "#         # Extract reviews from the page\n",
    "#         print(\"\\nExtracting reviews from content...\")\n",
    "#         reviews = extract_reviews_from_content(page_content)\n",
    "\n",
    "#         # Print results\n",
    "#         print(f\"\\nFound {len(reviews)} reviews:\")\n",
    "#         for idx, review in enumerate(reviews, 1):\n",
    "#             print(f\"\\nReview {idx}:\")\n",
    "#             print(f\"Author: {review['author']}\")\n",
    "#             print(f\"Rating: {review.get('rating', 'N/A')} stars\")\n",
    "#             print(f\"Review: {review['review']}\")\n",
    "#             print(\"-\" * 50)\n",
    "\n",
    "#         # Save results\n",
    "#         save = input(\"\\nWould you like to save the reviews to a file? (y/n): \")\n",
    "#         if save.lower() == 'y':\n",
    "#             filename = input(\"Enter filename (default: reviews.json): \").strip() or \"reviews.json\"\n",
    "#             save_reviews(reviews, filename)\n",
    "#             print(f\"Reviews saved to {filename}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {str(e)}\")\n",
    "#         print(\"Please check the URL and try again.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    url = input(\"Enter the URL to scrape: \")\n",
    "\n",
    "    # Extract page text from the URL\n",
    "    page_content = extract_text_from_url(url)\n",
    "    if page_content:\n",
    "        print(\"Page content extracted successfully.\")\n",
    "\n",
    "        # Extract reviews from the page content\n",
    "        reviews = extract_reviews_from_content(page_content)\n",
    "\n",
    "        if reviews:\n",
    "            print(f\"\\nFound {len(reviews)} reviews:\")\n",
    "            for idx, review in enumerate(reviews, 1):\n",
    "                print(f\"\\nReview {idx}:\")\n",
    "                print(f\"Author: {review['author']}\")\n",
    "                print(f\"Rating: {review.get('rating', 'N/A')} stars\")\n",
    "                print(f\"Review: {review['review']}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "            # Ask user if they want to save the reviews\n",
    "            save = input(\"\\nWould you like to save the reviews to a file? (y/n): \")\n",
    "            if save.lower() == 'y':\n",
    "                filename = input(\"Enter filename (default: reviews.json): \").strip() or \"reviews.json\"\n",
    "                save_reviews(reviews, filename)\n",
    "                print(f\"Reviews saved to {filename}\")\n",
    "        else:\n",
    "            print(\"No reviews found.\")\n",
    "    else:\n",
    "        print(\"Failed to extract page content.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
