{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests bs4 selenium time random cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cohere\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    "    ElementClickInterceptedException,\n",
    "    StaleElementReferenceException,\n",
    ")\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_css_selectors(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    css_selectors = []\n",
    "\n",
    "    review_keywords = r\"(review|comment|feedback|text|body|content|post|entry|description|testimonial|rev(iew)?|customer|summary)\"\n",
    "    author_keywords = r\"(author|user|name|profile|by|writer|creator|reviewer|posted\\sby|submitter)\"\n",
    "    rating_keywords = r\"(rating|stars|score|rank|grade|level|points|rate|review\\-score|feedback\\-rating)\"\n",
    "    pagination_keywords = r\"(next|pagination|nav|page|forward|load\\-more|show\\-more|continue|arrow\\-right|scroll\\-next)\"\n",
    "\n",
    "\n",
    "    def extract_selectors(element):\n",
    "        tag = element.name\n",
    "        classes = element.get(\"class\")\n",
    "        id_value = element.get(\"id\")\n",
    "        class_selector = f\".{'.'.join(classes)}\" if classes else None\n",
    "        id_selector = f\"#{id_value}\" if id_value else None\n",
    "\n",
    "    # Define a helper function for regex matching\n",
    "        def match_keywords(value, keywords):\n",
    "            return value and re.search(keywords, value, re.IGNORECASE)\n",
    "\n",
    "    # Check for class names\n",
    "        if classes:\n",
    "            for class_name in classes:\n",
    "                if match_keywords(class_name, review_keywords):\n",
    "                    css_selectors.append(f\".{class_name}\")\n",
    "                elif match_keywords(class_name, author_keywords):\n",
    "                    css_selectors.append(f\".{class_name}\")\n",
    "                elif match_keywords(class_name, rating_keywords):\n",
    "                    css_selectors.append(f\".{class_name}\")\n",
    "                elif match_keywords(class_name, pagination_keywords):\n",
    "                    css_selectors.append(f\".{class_name}\")\n",
    "\n",
    "    # Check for ID attributes\n",
    "        if id_value:\n",
    "            if match_keywords(id_value, review_keywords):\n",
    "                css_selectors.append(f\"#{id_value}\")\n",
    "            elif match_keywords(id_value, author_keywords):\n",
    "                css_selectors.append(f\"#{id_value}\")\n",
    "            elif match_keywords(id_value, rating_keywords):\n",
    "                css_selectors.append(f\"#{id_value}\")\n",
    "            elif match_keywords(id_value, pagination_keywords):\n",
    "                css_selectors.append(f\"#{id_value}\")\n",
    "\n",
    "    # Check for tag names\n",
    "        if match_keywords(tag, review_keywords):\n",
    "            css_selectors.append(tag)\n",
    "        elif match_keywords(tag, author_keywords):\n",
    "            css_selectors.append(tag)\n",
    "        elif match_keywords(tag, rating_keywords):\n",
    "            css_selectors.append(tag)\n",
    "        elif match_keywords(tag, pagination_keywords):\n",
    "            css_selectors.append(tag)\n",
    "\n",
    "    # Recursively check children elements\n",
    "        for child in element.children:\n",
    "            if hasattr(child, \"children\"):\n",
    "                extract_selectors(child)\n",
    "\n",
    "\n",
    "    extract_selectors(soup)\n",
    "    print(css_selectors)\n",
    "    return list(set(css_selectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(prompt):\n",
    "    \"\"\"Send a query to local Ollama server\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"llama3.2\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['response']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error communicating with Ollama: {str(e)}\")\n",
    "    \n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"Extract the first JSON object from text\"\"\"\n",
    "    try:\n",
    "        # First try to parse the entire text as JSON\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If that fails, try to find JSON object in the text\n",
    "        try:\n",
    "            # Find the first occurrence of a JSON-like structure\n",
    "            start_idx = text.find('{')\n",
    "            end_idx = text.rfind('}') + 1\n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = text[start_idx:end_idx]\n",
    "                return json.loads(json_str)\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            # If still no valid JSON, try cleaning the text\n",
    "            cleaned_text = re.sub(r'```json|```', '', text)  # Remove markdown code blocks\n",
    "            cleaned_text = cleaned_text.strip()\n",
    "            try:\n",
    "                return json.loads(cleaned_text)\n",
    "            except json.JSONDecodeError:\n",
    "                raise Exception(\"Could not extract valid JSON from response\")\n",
    "\n",
    "# def get_tag_suggestions(css_selectors):\n",
    "#     # Create a prompt that asks the model to identify relevant selectors\n",
    "#     prompt = f\"\"\"Given these CSS selectors from a website:\n",
    "# {json.dumps(css_selectors, indent=2)}\n",
    "\n",
    "# Analyze them and identify the most likely selectors for:\n",
    "# 1. Review text body\n",
    "# 2. Author name\n",
    "# 3. Rating element\n",
    "# 4. Next pagination button\n",
    "\n",
    "# Common patterns to look for:\n",
    "# - Review containers often have classes/IDs with words like 'review', 'comment', 'text', 'content', 'body'\n",
    "# - Author elements often contain 'author', 'user', 'name', 'by'\n",
    "# - Rating elements usually have 'rating', 'stars', 'score'\n",
    "# - Next page buttons typically include 'next', 'pagination', 'nav'\n",
    "\n",
    "# Return ONLY a JSON object in this exact format (no other text):\n",
    "# {{\n",
    "#     \"review_tag\": \"selector_for_review_body\",\n",
    "#     \"author_tag\": \"selector_for_author_name\",\n",
    "#     \"rating_tag\": \"selector_for_rating\",\n",
    "#     \"next_pagination_button_tag\": \"selector_for_next_button\"\n",
    "# }}\"\"\"\n",
    "\n",
    "#     # Get response from Ollama\n",
    "#     response = query_ollama(prompt)\n",
    "    \n",
    "#     return extract_json_from_text(response)\n",
    "\n",
    "def get_tag_suggestions(css_selectors, api_key):\n",
    "    # Initialize Cohere client\n",
    "    co = cohere.Client(api_key)\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"You are given a list of CSS selectors extracted from a website:\n",
    "{json.dumps(css_selectors, indent=2)}\n",
    "\n",
    "Your task is to analyze these selectors and determine the best matches for the following elements:\n",
    "1. Review text body\n",
    "2. Author name\n",
    "3. Rating element\n",
    "4. Next pagination button\n",
    "\n",
    "### Guidelines for Selection:\n",
    "- **Review Text Body:** Look for classes, IDs, or tags containing terms such as 'review', 'comment', 'text', 'content', 'body', 'feedback', 'testimonial', or similar keywords.\n",
    "- **Author Name:** Identify selectors containing words like 'author', 'user', 'name', 'profile', 'by', 'reviewer', 'creator', or 'submitter'.\n",
    "- **Rating Element:** Focus on selectors with terms like 'rating', 'stars', 'score', 'rank', 'grade', 'review-score', or similar indicators of numeric or star-based ratings.\n",
    "- **Next Pagination Button:** Look for terms such as 'next', 'pagination', 'nav', 'page', 'load-more', 'show-more', 'forward', 'arrow-right', or similar navigation elements.\n",
    "\n",
    "### Constraints:\n",
    "- Use regex patterns to identify relevant selectors for each element based on keyword matches in class names, IDs, and tag names.\n",
    "- Prioritize selectors with multiple keyword matches or stronger indicators.\n",
    "- Return only the most relevant selector for each category.\n",
    "\n",
    "### Expected Output Format:\n",
    "You must return only a JSON object in the following exact format:\n",
    "{{\n",
    "    \"review_tag\": \"selector_for_review_body\",\n",
    "    \"author_tag\": \"selector_for_author_name\",\n",
    "    \"rating_tag\": \"selector_for_rating\",\n",
    "    \"next_pagination_button_tag\": \"selector_for_next_button\"\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    # Query Cohere API\n",
    "    response = co.generate(\n",
    "        model='command-r-plus',  # Specify the model\n",
    "        prompt=prompt,\n",
    "        max_tokens=300,  # You can adjust max tokens based on response size\n",
    "    )\n",
    "\n",
    "    # Extract and return the JSON from the response\n",
    "    return json.loads(response.generations[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dynamic_popups(driver):\n",
    "    try:\n",
    "        potential_popups = driver.find_elements(By.CSS_SELECTOR, \"*\")\n",
    "        for element in potential_popups:\n",
    "            try:\n",
    "                style = element.get_attribute(\"style\")\n",
    "                if \"z-index\" in style and \"visibility: visible\" in style:\n",
    "                    close_buttons = element.find_elements(By.CSS_SELECTOR, \"button, a, span\")\n",
    "                    for button in close_buttons:\n",
    "                        if button.is_displayed() and button.is_enabled():\n",
    "                            button.click()\n",
    "                            time.sleep(1)\n",
    "                            return True\n",
    "                    action = ActionChains(driver)\n",
    "                    random_x = random.randint(0, driver.execute_script(\"return window.innerWidth;\"))\n",
    "                    random_y = random.randint(0, driver.execute_script(\"return window.innerHeight;\"))\n",
    "                    action.move_by_offset(random_x, random_y).click().perform()\n",
    "                    time.sleep(1)\n",
    "                    return True\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "            except Exception:\n",
    "                continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_reviews(url, review_tag, author_tag, rating_tag, next_page_button_tag):\n",
    "    # Set up Selenium WebDriver\n",
    "    service = Service(\"chromedriver.exe\")  # Update this path\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.maximize_window()  # Maximize window for better visibility\n",
    "\n",
    "    try:\n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)  # Wait for elements to load\n",
    "\n",
    "        all_reviews = []\n",
    "        page_number = 1  # Track the current page number for debugging\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Wait for the reviews section to load\n",
    "                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, review_tag)))\n",
    "\n",
    "                # Get the current page source and parse it with BeautifulSoup\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                # Find all review elements using the passed review_tag, author_tag, and rating_tag\n",
    "                review_elements = soup.select(review_tag)\n",
    "                author_elements = soup.select(author_tag)\n",
    "                rating_elements = soup.select(rating_tag)\n",
    "\n",
    "                # Extract reviews, authors, and ratings\n",
    "                for review, author, rating in zip(review_elements, author_elements, rating_elements):\n",
    "                    review_text = review.get_text(strip=True)\n",
    "                    author_name = author.get_text(strip=True)\n",
    "                    rating_score = rating.get(\"data-score\", \"N/A\")  # Extract 'data-score' or use 'N/A' if missing\n",
    "                    all_reviews.append({\n",
    "                        \"review\": review_text,\n",
    "                        \"author\": author_name,\n",
    "                        \"rating\": rating_score\n",
    "                    })\n",
    "\n",
    "                print(f\"Page {page_number} scraped successfully with {len(review_elements)} reviews.\")\n",
    "                page_number += 1\n",
    "\n",
    "                # Scroll the \"Next Page\" button into view and click it\n",
    "                try:\n",
    "                    next_page_button = driver.find_element(By.CSS_SELECTOR, next_page_button_tag)\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "                    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, next_page_button_tag))).click()\n",
    "                    time.sleep(2)  # Small pause to ensure the page loads\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(\"No more pages to scrape or 'Next Page' button not found.\")\n",
    "                    break\n",
    "                except ElementClickInterceptedException as e:\n",
    "                    print(f\"Click intercepted on page {page_number}: {str(e)}\")\n",
    "                    ActionChains(driver).move_to_element_with_offset(next_page_button, 0, 0).click().perform()\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping page {page_number}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # Ensure the browser is closed properly\n",
    "        driver.quit()\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter when ready, or Ctrl+C to exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching CSS selectors from the page...\n",
      "['#shopify-accelerated-checkout', '#shopify-accelerated-checkout-cart', '#shopify-accelerated-checkout-cart-grid-with-margin-top', '.image-reveal--mask', 'body', '.skip-to-content', '.close-sidebar__text', '.navigate-back', '.close-sidebar__text', '.sidebar__content', 'nav', '.close-sidebar__text', '.dynamic-checkout__content', 'shopify-accelerated-checkout-cart', '.cart-continue', '.page-content', '.mount-product-page', '.product-page', 'product-page', '.jdgm-preview-badge', '.jdgm-prev-badge', '.jdgm-prev-badge__stars', '.jdgm-prev-badge__text', '.text-size--smaller', '.product__description', '.product-variant__name', '.add-to-cart__text', 'shopify-accelerated-checkout', '.text-size--smaller', '.toggle__content', '.product__content', '.content', '.content', '.content', '.jdgm-review-widget', '#judgeme_product_reviews', '.jdgm-rev-widg', '.jdgm-rev-widg__header', '.jdgm-rev-widg__title', '.jdgm-rev-widg__summary', '.jdgm-rev-widg__summary-stars', '.jdgm-rev-widg__summary-text', '.jdgm-write-rev-link', '.jdgm-histogram__bar-content', '.jdgm-histogram__bar-content', '.jdgm-histogram__bar-content', '.jdgm-histogram__bar-content', '.jdgm-histogram__bar-content', '.jdgm-rev-widg__sort-wrapper', '.jdgm-rev-widg__body', '.jdgm-rev-widg__reviews', '.jdgm-rev', '.jdgm-rev__header', '.jdgm-rev__icon', '.jdgm-rev__rating', '.jdgm-rev__timestamp', '.jdgm-rev__br', '.jdgm-rev__buyer-badge-wrapper', '.jdgm-rev__buyer-badge', '.jdgm-rev__author-wrapper', '.jdgm-rev__author', '.jdgm-rev__location', '.jdgm-rev__source', '.jdgm-rev__content', '.jdgm-rev__custom-form', '.jdgm-rev__title', '.jdgm-rev__body', '.jdgm-rev__pics', '.jdgm-rev__vids', '.jdgm-rev__actions', '.jdgm-rev__social', '.jdgm-rev__votes', '.jdgm-rev__reply', '.jdgm-rev', '.jdgm-rev__header', '.jdgm-rev__icon', '.jdgm-rev__rating', '.jdgm-rev__timestamp', '.jdgm-rev__br', '.jdgm-rev__buyer-badge-wrapper', '.jdgm-rev__buyer-badge', '.jdgm-rev__author-wrapper', '.jdgm-rev__author', '.jdgm-rev__location', '.jdgm-rev__source', '.jdgm-rev__content', '.jdgm-rev__custom-form', '.jdgm-rev__title', '.jdgm-rev__body', '.jdgm-rev__pics', '.jdgm-rev__vids', '.jdgm-rev__actions', '.jdgm-rev__social', '.jdgm-rev__votes', '.jdgm-rev__reply', '.jdgm-rev', '.jdgm-rev__header', '.jdgm-rev__icon', '.jdgm-rev__rating', '.jdgm-rev__timestamp', '.jdgm-rev__br', '.jdgm-rev__buyer-badge-wrapper', '.jdgm-rev__buyer-badge', '.jdgm-rev__author-wrapper', '.jdgm-rev__author', '.jdgm-rev__location', '.jdgm-rev__source', '.jdgm-rev__content', '.jdgm-rev__custom-form', '.jdgm-rev__title', '.jdgm-rev__body', '.jdgm-rev__pics', '.jdgm-rev__vids', '.jdgm-rev__actions', '.jdgm-rev__social', '.jdgm-rev__votes', '.jdgm-rev__reply', '.jdgm-rev', '.jdgm-rev__header', '.jdgm-rev__icon', '.jdgm-rev__rating', '.jdgm-rev__timestamp', '.jdgm-rev__br', '.jdgm-rev__buyer-badge-wrapper', '.jdgm-rev__buyer-badge', '.jdgm-rev__author-wrapper', '.jdgm-rev__author', '.jdgm-rev__location', '.jdgm-rev__source', '.jdgm-rev__content', '.jdgm-rev__custom-form', '.jdgm-rev__title', '.jdgm-rev__body', '.jdgm-rev__pics', '.jdgm-rev__vids', '.jdgm-rev__actions', '.jdgm-rev__social', '.jdgm-rev__votes', '.jdgm-rev__reply', '.jdgm-rev', '.jdgm-rev__header', '.jdgm-rev__icon', '.jdgm-rev__rating', '.jdgm-rev__timestamp', '.jdgm-rev__br', '.jdgm-rev__buyer-badge-wrapper', '.jdgm-rev__buyer-badge', '.jdgm-rev__author-wrapper', '.jdgm-rev__author', '.jdgm-rev__location', '.jdgm-rev__content', '.jdgm-rev__custom-form', '.jdgm-rev__title', '.jdgm-rev__body', '.jdgm-rev__pics', '.jdgm-rev__vids', '.jdgm-rev__actions', '.jdgm-rev__social', '.jdgm-rev__votes', '.jdgm-rev__reply', '.jdgm-paginate__page', '.jdgm-paginate__page', '.jdgm-paginate__page', '.jdgm-paginate__page', '.jdgm-paginate__next-page', '.jdgm-paginate__page', '.jdgm-paginate__last-page', '.jdgm-rev-widg__paginate-spinner-wrapper', '#shopify-section-text-columns-with-icons', '.text-size--larger', '.footer-links-body', '.footer-links-body', '.footer-links-body', '.footer-links-body', '.footer-links-body', '.text-size--larger', '.footer-links-body', '.footer-links-body', '.footer-links-body', '.footer-links-body', '.footer-links-body', '.footer-links-body', '.newsletter-text', '.footer-item--text', '.popup-text', '.page-overlay']\n",
      "Found 75 unique CSS selectors\n",
      "\n",
      "Analyzing selectors with Cohere...\n",
      "Error: Expecting value: line 1 column 1 (char 0)\n",
      "Please check the selectors and try again.\n"
     ]
    }
   ],
   "source": [
    "def main(url):\n",
    "    # Check if Ollama server is running\n",
    "    try:\n",
    "        requests.get(\"http://localhost:11434/api/version\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Error: Cannot connect to Cohere server.\")\n",
    "        return\n",
    "\n",
    "    # First, fetch all CSS selectors from the page\n",
    "    print(\"Fetching CSS selectors from the page...\")\n",
    "    css_selectors = fetch_css_selectors(url)\n",
    "    print(f\"Found {len(css_selectors)} unique CSS selectors\")\n",
    "    \n",
    "    # Get tag suggestions from Ollama\n",
    "    print(\"\\nAnalyzing selectors with Cohere...\")\n",
    "    try:\n",
    "        tag_suggestions = get_tag_suggestions(css_selectors,api)\n",
    "        print(\"\\nCohere suggested these selectors:\")\n",
    "        print(json.dumps(tag_suggestions, indent=2))\n",
    "        \n",
    "        # Allow user to modify suggestions if needed\n",
    "        print(\"\\nWould you like to:\")\n",
    "        print(\"1. Proceed with these selectors\")\n",
    "        print(\"2. Modify the selectors\")\n",
    "        print(\"3. Abort\")\n",
    "        choice = input(\"Enter your choice (1/2/3): \")\n",
    "        \n",
    "        if choice == \"2\":\n",
    "            print(\"\\nEnter new selectors (press Enter to keep existing one):\")\n",
    "            for key, value in tag_suggestions.items():\n",
    "                new_value = input(f\"{key} [{value}]: \").strip()\n",
    "                if new_value:\n",
    "                    tag_suggestions[key] = new_value\n",
    "        elif choice == \"3\":\n",
    "            print(\"Aborting scraping process.\")\n",
    "            return\n",
    "        elif choice != \"1\":\n",
    "            print(\"Invalid choice. Aborting.\")\n",
    "            return\n",
    "        \n",
    "        # Fetch reviews using the suggested tags\n",
    "        print(\"\\nStarting review collection...\")\n",
    "        reviews = fetch_all_reviews(\n",
    "            url,\n",
    "            tag_suggestions['review_tag'],\n",
    "            tag_suggestions['author_tag'],\n",
    "            tag_suggestions['rating_tag'],\n",
    "            tag_suggestions['next_page_button_tag']\n",
    "        )\n",
    "        \n",
    "        # Print reviews\n",
    "        print(f\"\\nCollected {len(reviews)} reviews:\")\n",
    "        for idx, review in enumerate(reviews, 1):\n",
    "            print(f\"\\nReview {idx}:\")\n",
    "            print(f\"Author: {review['author']}\")\n",
    "            print(f\"Rating: {review['rating']} stars\")\n",
    "            print(f\"Review: {review['review']}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        # Offer to save reviews to file\n",
    "        save = input(\"\\nWould you like to save the reviews to a file? (y/n): \")\n",
    "        if save.lower() == 'y':\n",
    "            filename = input(\"Enter filename (default: reviews.json): \").strip() or \"reviews.json\"\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(reviews, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"Reviews saved to {filename}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Please check the selectors and try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # # Instructions for setting up Ollama\n",
    "    # print(\"Before running this script, make sure:\")\n",
    "    # print(\"1. Ollama is installed (https://ollama.ai/download)\")\n",
    "    # print(\"2. You've pulled the llama3.2 model: Run 'ollama pull llama3.2'\")\n",
    "    # print(\"3. Ollama server is running: Run 'ollama serve' in a terminal\")\n",
    "    print(\"\\nPress Enter when ready, or Ctrl+C to exit\")\n",
    "    input()\n",
    "    \n",
    "    url = input(\"Enter the URL to scrape: \")\n",
    "    main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
